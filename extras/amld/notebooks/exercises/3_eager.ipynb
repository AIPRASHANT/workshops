{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"name": "3_eager", "provenance": [], "collapsed_sections": [], "toc_visible": true}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "metadata": {"id": "nOLvC15Xfl_M", "colab_type": "text"}, "source": ["# TensorFlow Eager\n", "\n", "With TensorFlow 2, \"[eager](https://www.tensorflow.org/guide/eager) execution\" mode is enabled by default. This means that every tensor computation is executed directly as it is defined in Python. This is in line with many other frameworks (such as `numpy`).\n", "\n", "Note that in earlier versions of TensorFlow, computations were separated into a \"graph construction phase\" and a \"graph execution phase\", which caused a steep learning curve in using the framework.\n", "\n", "The new \"eager execution\" mode is intuitive to use and ideal for model development and experimentation.\n", "\n", "For this Colab it's handy to keep [TensorFlow's API documentation](https://www.tensorflow.org/api_docs/python/tf) open in a separate browser tab."]}, {"cell_type": "code", "metadata": {"id": "jHGIMZC5-JSR", "colab_type": "code", "outputId": "021a4046-c83a-4e8c-f7f9-d75d1533cd6c", "executionInfo": {"status": "ok", "timestamp": 1579905183297, "user_tz": 480, "elapsed": 910, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# In Jupyter, you would need to install TF 2 via !pip.\n", "%tensorflow_version 2.x"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "bhn7C_aX1Q-6", "colab_type": "code", "outputId": "371fc20b-02dc-4ed5-c806-6eccfc0da40d", "executionInfo": {"status": "ok", "timestamp": 1579905192082, "user_tz": 480, "elapsed": 9682, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["import json, os\n", "import numpy as np\n", "from matplotlib import pyplot as plt\n", "import tensorflow as tf\n", "\n", "# Tested with TensorFlow 2.1.0\n", "print('version={}, CUDA={}, GPU={}, TPU={}'.format(\n", "    tf.__version__, tf.test.is_built_with_cuda(),\n", "    # GPU attached?\n", "    len(tf.config.list_physical_devices('GPU')) > 0,\n", "    # TPU accessible? (only works on Colab)\n", "    'COLAB_TPU_ADDR' in os.environ))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "V5bA7N788eiT", "colab_type": "text"}, "source": ["> **Attention:** Please avoid using the TPU runtime (`TPU=True`) for now. The notebook contains an optional part on TPU usage at the end if you're interested. You can change the runtime via: \"Runtime > Change runtime type > Hardware Accelerator\" in Colab."]}, {"cell_type": "code", "metadata": {"id": "UwtuKp3z-eqE", "colab_type": "code", "colab": {}}, "source": ["# Load data from Drive (Colab only).\n", "data_path = '/content/gdrive/My Drive/amld_data/zoo_img'\n", "\n", "# Or, you can load data from different sources, such as:\n", "# From your local machine:\n", "# data_path = './amld_data'\n", "\n", "# Or use a prepared dataset from Cloud (Colab only).\n", "# See https://console.cloud.google.com/storage/browser/amld-datasets\n", "# - 50k training examples, including pickled DataFrame.\n", "# data_path = 'gs://amld-datasets/zoo_img_small'"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "itNiEr6rUXYa", "colab_type": "code", "outputId": "55dde399-7bce-4ef3-a4a8-96e5a6a5eb99", "executionInfo": {"status": "ok", "timestamp": 1579905237683, "user_tz": 480, "elapsed": 55268, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 730}}, "source": ["# (Copied from ./2_keras.ipynb)\n", "if data_path.startswith('/content/gdrive/'):\n", "  from google.colab import drive\n", "  drive.mount('/content/gdrive')\n", "if data_path.startswith('gs://'):\n", "  from google.colab import auth\n", "  auth.authenticate_user()\n", "  !gsutil ls -lh \"$data_path\"\n", "else:\n", "  !ls -lh \"$data_path\""], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "_6RrqVkp4LSH", "colab_type": "text"}, "source": ["## Tensors\n", "\n", "A Tensor can describe a scalar, vector, matrix, or higher dimensional data (also see\n", " [TF guide - Tensors](https://www.tensorflow.org/guide/tensors)).  The essential Tensor types include:\n", "\n", "* `tf.constant`\n", "* `tf.Variable`\n", "* `tf.SparseTensor`\n", "* More tensor types that we won't discuss in this Colab `tf.RaggedTensor`, `tf.TensorArray`.\n", "\n", "The essential Tensor attributes are:\n", "\n", "* Rank - number of dimensions\n", "* Shape - number of elements in each dimension\n", "* Data type - for example `tf.float32`: **must be the same for every dimension**\n", "\n", "Let's look at the different Tensor types."]}, {"cell_type": "markdown", "metadata": {"id": "1NcZ-XgJilcq", "colab_type": "text"}, "source": ["### Tensor types"]}, {"cell_type": "markdown", "metadata": {"id": "Cpqcn--jyLq3", "colab_type": "text"}, "source": ["**`tf.constant`** - A basic immutable Tensor\n", "\n", "We can define a constant tensor with a shape of `[12]` (i.e. a vector with 12 elements)."]}, {"cell_type": "code", "metadata": {"id": "M5xfkuTk1ent", "colab_type": "code", "outputId": "96441b02-c7d5-4be9-cf62-bf771da21d91", "executionInfo": {"status": "ok", "timestamp": 1579905237684, "user_tz": 480, "elapsed": 55258, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["tensor12 = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n", "tensor12"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "STHFyuWPiwzK", "colab_type": "code", "outputId": "ed5e3af5-623d-4e87-ca43-db5211e65cc6", "executionInfo": {"status": "ok", "timestamp": 1579905237684, "user_tz": 480, "elapsed": 55249, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Get the tensor data as a numpy ndarray:\n", "tensor12.numpy()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "9r33ZdQY_Y8u", "colab_type": "text"}, "source": ["**`tf.Variable`** - A mutable Tensor\n", "\n", "If we need to store state (e.g. the weight parameters of a network), then we use a mutable Tensor callled `tf.Variable`."]}, {"cell_type": "code", "metadata": {"id": "kTbpmcJsAdE9", "colab_type": "code", "outputId": "16c4436d-2f57-4e3f-af4b-4da5621ceca5", "executionInfo": {"status": "ok", "timestamp": 1579905244691, "user_tz": 480, "elapsed": 62247, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Define a Variable with a known initial value.\n", "weight = tf.Variable(0, dtype=float, name='weight')\n", "weight"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "cPF3EOj9An9X", "colab_type": "text"}, "source": ["For updates, we can then make use of the `assign` operations TF provides.\n", "\n", "Particularly, we can use operations like `.assign`, `.assign_add` and `.assign_sub`."]}, {"cell_type": "code", "metadata": {"id": "SN96XoqtDR_d", "colab_type": "code", "outputId": "1715e57b-f10a-46f3-ffc9-fbe4ea85fc89", "executionInfo": {"status": "ok", "timestamp": 1579905244692, "user_tz": 480, "elapsed": 62239, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# YOUR ACTION REQUIRED:\n", "# 1. Create a variable called `new_var`.\n", "# 2. Assign the value 1531 to `new_var`.\n", "# 3. Use `.assign_sub` to subtract 194.\n", "new_var =\n", "new_var.\n", "new_var.\n", "print('Variable:', new_var)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "WEQ_QzXSrSfd", "colab_type": "code", "outputId": "072dd842-8b36-4a35-e837-ed1542c8f218", "executionInfo": {"status": "ok", "timestamp": 1579905244693, "user_tz": 480, "elapsed": 62231, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Creating a variable and incrementing it:\n", "v1 = tf.Variable(0)\n", "v1.assign_add(1)\n", "v1"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "-trJmdNJrUyl", "colab_type": "code", "outputId": "19c82549-5d4e-48da-a53b-1232fadd3d96", "executionInfo": {"status": "ok", "timestamp": 1579905244693, "user_tz": 480, "elapsed": 62223, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# MISTAKE: The following two statements will create a variable with the\n", "# value 0 and then a tensor that is the variable plus one. The reference to the\n", "# original variable is lost and any code using the reference to the original\n", "# `v2` will still see the value 0.\n", "v2 = tf.Variable(0)\n", "v2 = v2 + 1\n", "v2"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "YUM64n-oEv6L", "colab_type": "text"}, "source": ["**`tf.SparseTensor`** - A sparse representation Tensor\n", "\n", "Sparse tensors can have an arbitrarily large shape, but they store only values that are different from the default value (usually `0`). This type is very useful for some applications, for example to represent a word with a one-hot encoding from a large dictionary.\n", "\n", "Note that some TF functions (see [`tf.sparse`](https://www.tensorflow.org/api_docs/python/tf/sparse) module) only work with sparse tensors, while most TF functions except regular tensors as input.\n"]}, {"cell_type": "code", "metadata": {"id": "0hOin0LxFDan", "colab_type": "code", "colab": {}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Complete the arguments to `tf.SparseTensor` in the following statement to\n", "# define a 3x3 matrix with ones on the \\ diagonal and zeros everywhere else. \n", "# Hint: When complete type the \"()\" below, Colab will show the function's\n", "# documentation.\n", "#sparse_eye3 = tf.SparseTensor\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "9C253JwMmwmb", "colab_type": "code", "outputId": "79b3f7f9-870a-46bb-82ce-a1926f066ada", "executionInfo": {"status": "ok", "timestamp": 1579905244695, "user_tz": 480, "elapsed": 62209, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 87}}, "source": ["# Note that to display the values, we need to convert the sparse\n", "# tensor to normal `tf.Tensor` (a \"dense\" tensor):\n", "tf.sparse.to_dense(sparse_eye3)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "_7URJpig4WLF", "colab_type": "text"}, "source": ["### Operator overloading & Broadcasting"]}, {"cell_type": "markdown", "metadata": {"id": "hQXNdqiVHjWo", "colab_type": "text"}, "source": ["In general, operator overloading allows to define custom behavior for basic operators like: -, +, /, and *. The result might depend on the arguments':\n", "* Order\n", "* Data type\n", "* Content\n", "\n", "TensorFlow makes use of operator overloading to simplify the core API as we will see below.\n", "\n", "In addition, it makes use of something called Broadcasting.\n", "\n", "> \"Broadcasting is the process of making arrays with different shapes that have compatible shapes for arithmetic operations. The terminology is borrowed from [Numpy broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).\" - see https://www.tensorflow.org/xla/broadcasting\n", "\n", "Overall, this allows us to succinctly and efficiently operate with tensors of different shapes and types.  "]}, {"cell_type": "code", "metadata": {"id": "h03uPhiE3cqe", "colab_type": "code", "outputId": "4ef0906f-e52f-4834-e963-a6e949351abf", "executionInfo": {"status": "ok", "timestamp": 1579905244695, "user_tz": 480, "elapsed": 62199, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Broadcasting + operator overloading: Try to write the line below more \n", "# succinctly.\n", "\n", "# YOUR ACTION REQUIRED: Simplify the given statement by making use of TF's\n", "# operator overloading and Broadcasting.\n", "tensor12_plus_1 = tf.add(tensor12, tf.ones(shape=tensor12.shape, dtype=tf.int32))\n", "tensor12_plus_1"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "I52dN5v8B5FK", "colab_type": "text"}, "source": ["TensorFlow accepts Python numbers or Numpy arrays in most places and converts them to tensors on the fly."]}, {"cell_type": "code", "metadata": {"id": "HRRAemdxCBeB", "colab_type": "code", "outputId": "fca70ad0-49d8-41a3-e3d0-691d92ed0e90", "executionInfo": {"status": "ok", "timestamp": 1579905244696, "user_tz": 480, "elapsed": 62191, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Try to replace one or both of the arguments with a\n", "# tf.constant() or with a np.array() and see what happens. Use different shapes.\n", "tf.add(1, 2)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "57LGLtjEqUlb", "colab_type": "code", "outputId": "a017c45c-ba79-4dce-b572-7d4342942888", "executionInfo": {"status": "ok", "timestamp": 1579905244696, "user_tz": 480, "elapsed": 62182, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 123}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Use broadcasting to generate an array like this:\n", "# [[11, 12, 13, ...],\n", "#  [21, 22, 23, ...],\n", "#  [31, 32, 33, ...],\n", "#  ...,\n", "# ]\n", "# (Tip: use tf.range() & tf.reshape() or tf.expand_dims())\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "dZnMYsUZRSVP", "colab_type": "text"}, "source": ["When applying an operation to Tensors they must be of the same datatype. In any other case, you might see a ValueError like below."]}, {"cell_type": "code", "metadata": {"id": "ShDUlar_0-Nl", "colab_type": "code", "outputId": "6919feab-6dc8-490f-ba07-c4b28c59c442", "executionInfo": {"status": "ok", "timestamp": 1579905244697, "user_tz": 480, "elapsed": 62175, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 70}}, "source": ["# YOUR ACTION REQUIRED: Try to change the datatype of one of the tensors to \n", "# fix the ValueError.\n", "multiplier = tf.constant(1.5)\n", "tensor12 * multiplier\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "1Ubegrgt4gAy", "colab_type": "text"}, "source": ["### Accessing elements"]}, {"cell_type": "markdown", "metadata": {"id": "p_Fcd-4YUSVv", "colab_type": "text"}, "source": ["Accessing individual elements of a 2D tensor."]}, {"cell_type": "code", "metadata": {"id": "ZhimrP5T1MZc", "colab_type": "code", "outputId": "10d043db-7f89-4c13-f638-2368afda74ac", "executionInfo": {"status": "ok", "timestamp": 1579905244697, "user_tz": 480, "elapsed": 62163, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 70}}, "source": ["# A batch of 3 zero padded vectors with different length:\n", "# first vector = [1, 2, 3]\n", "# second vector = [2, 4, 5, 8]\n", "# third vector = [3, 6]\n", "batch = tf.constant([[1, 2, 3, 0, 0],\n", "                     [2, 4, 6, 8, 0],\n", "                     [3, 6, 0, 0, 0]])\n", "\n", "# Length of the vectors (without zero padding at end).\n", "lengths = tf.constant([3, 4, 2])\n", "\n", "# The FIRST elements can be accessed by using Python's overloaded indexing...\n", "batch[0:3, 0:1].numpy()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "Z7plJ-FgtjFM", "colab_type": "code", "outputId": "71ecdc7f-6d9c-4cbe-f6a9-00b6aa093340", "executionInfo": {"status": "ok", "timestamp": 1579905244698, "user_tz": 480, "elapsed": 62156, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 70}}, "source": ["# ... or explicitly using the TF SPI.\n", "tf.slice(batch, [0, 0], [3, 1]).numpy()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "YipD-4eHV8Jk", "colab_type": "text"}, "source": ["Accessing the LAST (non-padded) element within every sequence is somewhat more involved.\n", "\n", "You need to specify both the indices in the first and the second dimension and then use `tf.gather_nd()`."]}, {"cell_type": "code", "metadata": {"id": "agj5eLJ41RL0", "colab_type": "code", "outputId": "5d041810-155e-4879-dd14-35c6679218f2", "executionInfo": {"status": "ok", "timestamp": 1579905244699, "user_tz": 480, "elapsed": 62148, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Accessing the last elements is slightly more involved:\n", "indices_0 = list(range(3))\n", "indices_1 = lengths - 1\n", "\n", "# -> Go check out the documentation of tf.gather_nd().\n", "tf.gather_nd(batch, tf.transpose([indices_0, indices_1]))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "ljwNtQiZXWhZ", "colab_type": "text"}, "source": ["Below you have an integer tensor and then an expression that is set True for all elements that are odd.\n", "\n", "Try to print those elements using the operations `tf.where()` and `tf.gather()`.\n"]}, {"cell_type": "code", "metadata": {"id": "CAt9oxPD1dZX", "colab_type": "code", "outputId": "3c3ce190-d276-4d11-c257-e4cc904e166d", "executionInfo": {"status": "ok", "timestamp": 1579905244699, "user_tz": 480, "elapsed": 62140, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 105}}, "source": ["numbers = tf.range(1, 11)\n", "odd_condition = tf.logical_not(tf.equal(0, tf.math.mod(numbers, 2)))\n", "\n", "# YOUR ACTION REQUIRED:\n", "# Provide the correct expression for `odd_indices` and `odd_numbers`.\n", "# You can use `tf.where` and `tf.gather` to this.\n", "odd_indices =\n", "odd_numbers =\n", "odd_numbers.numpy()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "2GGZ-cbI4u48", "colab_type": "text"}, "source": ["### Shape manipulation"]}, {"cell_type": "markdown", "metadata": {"id": "AOUlArs5CVaX", "colab_type": "text"}, "source": ["**Basic reshaping**\n", "\n", "We can reshape a tensor like `tensor12` into a 2x6 format in the following way."]}, {"cell_type": "code", "metadata": {"id": "oKm8mxl0txLr", "colab_type": "code", "outputId": "220da090-582e-4816-adb5-3487f15f950c", "executionInfo": {"status": "ok", "timestamp": 1579905244700, "user_tz": 480, "elapsed": 62132, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 70}}, "source": ["tf.reshape(tensor12, [2, 6])"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "Ax6ssgxvuOCj", "colab_type": "code", "outputId": "b254ec69-bb45-4ff0-9201-3cb389ae178d", "executionInfo": {"status": "ok", "timestamp": 1579905244701, "user_tz": 480, "elapsed": 62124, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 70}}, "source": ["# Alternatively, you can let TF figure out one of the dimensions:\n", "tf.reshape(tensor12, [-1, 6])"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "eo4JoQ6oGMSP", "colab_type": "text"}, "source": ["You can access the underlying data as a **numpy** array. Note the change in notation - tensors don't have methods for shape transformation etc, as opposed to numpy arrays."]}, {"cell_type": "code", "metadata": {"id": "6EvEMlDRt1D9", "colab_type": "code", "outputId": "dd962a56-ab44-401a-a943-59e2f785408a", "executionInfo": {"status": "ok", "timestamp": 1579905244701, "user_tz": 480, "elapsed": 62115, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 52}}, "source": ["tensor12.numpy().reshape([2, 6])"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "cedGQWVNRFze", "colab_type": "text"}, "source": ["**`tf.squeeze()`**\n", "\n", "What does `tf.squeeze()` do? Try it out on `tensor12_3` defined below!"]}, {"cell_type": "code", "metadata": {"id": "lkHpJaFN1HED", "colab_type": "code", "outputId": "bfd2b452-90bb-456a-b096-3d92c41035b9", "executionInfo": {"status": "ok", "timestamp": 1579905245011, "user_tz": 480, "elapsed": 62416, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["tensor12_3 = tf.reshape(tensor12, [3, 2, 2, 1])\n", "\n", "# YOUR ACTION REQUIRED: Apply tf.squeeze() and try to understand what's \n", "# happening.\n", "\n", "tensor12_3.shape \n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "mE32D1RhZ6R2", "colab_type": "text"}, "source": ["## Training a TF model "]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "jsw7kYfPZ5bw"}, "source": ["**Automatic differentiation with `tf.GradientTape`**\n", "\n", "Many optimization problems require the computation of gradients. For this purpose, TF supports automatic differentiation by using a  \"tape\" to record all operations executed inside the `tf.GradientTape` context.\n", "This log of operations can then be used to compute the gradients with respect to given variables (see [TF Tutorial on Automatic differentiation](https://www.tensorflow.org/tutorials/eager/automatic_differentiation)).\n", "\n", "Let's look at a concrete example for using this."]}, {"cell_type": "markdown", "metadata": {"id": "75mlg4YO4_UB", "colab_type": "text"}, "source": ["### Machinery to backprop gradients"]}, {"cell_type": "markdown", "metadata": {"id": "P6ZM_iq7EbcV", "colab_type": "text"}, "source": ["Let's see how this works in practice. Suppose our goal is to compute the square root of $2$ by utilizing the multiplication operation and the `GradientTape` mechanism.\n", "\n", "$x = \\pm\\sqrt{2} \\Leftrightarrow x^2 = 2$\n", "\n", "Then we define a \"loss\" : a numerical quantity that always gets smaller (decreases monotonically) when we get closer to the correct solution:\n", "\n", "$loss = (x^2 - 2)^2 \\geq 0$\n", "\n", "Finally, we compute the gradient of the loss with respect to x. This gradient will be positive if increasing x increases the loss, and negative if increasing x decreases the loss. This means that we can decrease the loss (=getting closer to the solution) by taking a *small* step against the gradient.\n", "\n", "Note that step size (\"learning rate\") $\\eta$ matters : If it is too large, we \"overshoot\", if it is too small, then we need to take a lot of steps to get to the correct value. This method is called **gradient descent** and is the cornerstone of most modern machine learning.\n", "\n", "$x:= x - \\eta * \\triangledown_x loss$\n", "\n", "Furthermore, we assume an initial guess of $x = 1.5$."]}, {"cell_type": "code", "metadata": {"id": "4gyWUX1k8LSI", "colab_type": "code", "outputId": "b312513f-2678-42e6-e596-6c31441b778b", "executionInfo": {"status": "ok", "timestamp": 1579905245334, "user_tz": 480, "elapsed": 62730, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 561}}, "source": ["# GradientTape computes gradients with respect to variables. So, we need to\n", "# define `x` as a tf.Variable.\n", "# (Note that gradient computation would return None with dtype=int)\n", "x = tf.Variable(1.5, dtype=tf.float32)\n", "f = lambda x: x * x\n", "x_squared_target = 2.0\n", "\n", "learning_rate = 0.1\n", "\n", "# Keep values of `x` and `losses` for plotting.\n", "xs = [x.numpy()]\n", "losses = []\n", "for i in range(10):\n", "  with tf.GradientTape() as tape:\n", "    # Compute function value.\n", "    x_squared = f(x)\n", "    # Loss indicates how far off our current guess is.\n", "    # Minimizing loss == finding better value for `x`.\n", "    loss = tf.square(x_squared - x_squared_target)\n", "  grad = tape.gradient(loss, x)\n", "  x.assign_add(-learning_rate * grad)\n", "  xs.append(x.numpy())\n", "  losses.append(loss.numpy())\n", "\n", "plt.figure()\n", "plt.plot(xs, 'r-')\n", "sg = xs[-1]/abs(xs[-1])\n", "plt.plot([0, len(xs) - 1], [sg*np.sqrt(x_squared_target)]*2, 'k--')\n", "plt.figure()\n", "plt.plot(losses)\n", "plt.gca().set_title('x (red) & loss (blue)');\n", "plt.xlabel('#Steps')\n", "plt.ylabel('Loss')\n", "print('final difference to solution: {}'.format(\n", "    abs(x.numpy() - x_squared_target**.5)))\n", "\n", "# YOUR ACTION REQUIRED:\n", "# Try changing the initial value and the learning rate and see what happens.\n", "# Tip: If you can't converge for some values, try clipping the gradients with\n", "# `tf.clip_by_norm()`."], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "QQNMrLLHITgE", "colab_type": "text"}, "source": ["### Training a linear model"]}, {"cell_type": "markdown", "metadata": {"id": "-FQfAY1yIHRH", "colab_type": "text"}, "source": ["Now let's use gradients to reimplement the linear model from [2_keras.ipynb](https://github.com/tensorflow/workshops/tree/master/extras/amld/notebooks/solutions/2_keras.ipynb)\n", "\n", "1. Specifying the training data and labels.\n", "2. Reading and parsing the stored training data into a TF supported format.\n", "3. Training our linear NN model using SGD and the data provided by the previous step. "]}, {"cell_type": "markdown", "metadata": {"id": "JaOea4KP5IDe", "colab_type": "text"}, "source": ["**1. Specifying the training data and labels.**"]}, {"cell_type": "code", "metadata": {"id": "D9Lqv4f0IUvk", "colab_type": "code", "outputId": "59e3fad0-bb79-4a54-9c91-413096a48dcb", "executionInfo": {"status": "ok", "timestamp": 1579905246000, "user_tz": 480, "elapsed": 63384, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 87}}, "source": ["labels = [label.strip() for label \n", "          in tf.io.gfile.GFile('{}/labels.txt'.format(data_path))]\n", "counts = json.load(tf.io.gfile.GFile('{}/counts.json'.format(data_path)))\n", "print('Labels({:d}):\\n\\t{}'.format(len(labels), labels))\n", "print('Counts:\\n\\t{}'.format(counts))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "zDKSey387ZUj", "colab_type": "text"}, "source": ["**2. Reading and parsing the stored data into a TF supported format.**"]}, {"cell_type": "code", "metadata": {"id": "3jnHZS8L6hKQ", "colab_type": "code", "outputId": "77be3c3f-f55c-471a-e1eb-69d7a2068930", "executionInfo": {"status": "ok", "timestamp": 1579905246751, "user_tz": 480, "elapsed": 64125, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 52}}, "source": ["# (copied from ./2_keras.ipynb -- see there for comments)\n", "feature_spec = {\n", "    'label': tf.io.FixedLenFeature(shape=[1], dtype=tf.int64),\n", "    'img_64': tf.io.FixedLenFeature(shape=[64, 64], dtype=tf.int64),\n", "}\n", "\n", "def parse_example(serialized_example):\n", "  features = tf.io.parse_single_example(serialized_example, feature_spec)\n", "  \n", "  label = features.pop('label')\n", "  label = tf.one_hot(tf.squeeze(label), len(labels))\n", "  \n", "  features['img_64'] = tf.cast(features['img_64'], tf.float32) / 255.\n", "  return features['img_64'], label\n", "\n", "batch_size = 100\n", "steps_per_epoch = counts['train'] // batch_size\n", "\n", "# Create datasets from `TFRecord` files.\n", "dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(\n", "    '{}/train-*'.format(data_path)))\n", "dataset = dataset.map(parse_example)\n", "dataset = dataset.batch(batch_size).repeat()\n", "\n", "# Read a single example and display shapes.\n", "for img_feature, label in dataset:\n", "  break\n", "print('img_feature.shape (batch_size, image_height, image_width) =', \n", "      img_feature.shape)\n", "print('label.shape (batch_size, number_of_labels) =', label.shape)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "XiXOBykV7-fL", "colab_type": "text"}, "source": ["**Defining the weights and biases.**\n", "\n", "The linear model is defined by the following computation:\n", "\n", "$$y = Wx + b$$\n", "\n", "With\n", "- $y$: Probabilities of the output classes (should approach the one-hot encoded labels).\n", "- $x$: The input (pixel intensities).\n", "- $W$, $b$: model parameters to be learnt via gradient descent."]}, {"cell_type": "code", "metadata": {"id": "lUH4EyKlQbM_", "colab_type": "code", "outputId": "1d3dff9a-3061-4029-efa6-3c51a3200342", "executionInfo": {"status": "ok", "timestamp": 1579905246752, "user_tz": 480, "elapsed": 64115, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Define the variables with the correct dimensions.\n", "W = tf.Variable(tf.random.normal(shape=(\n", "    img_feature.shape[1] * img_feature.shape[2], label.shape[1])))\n", "b = tf.Variable(tf.random.normal(shape=(label.shape[1], )))\n", "W.shape, b.shape"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "vu0kZiUB8SRE", "colab_type": "text"}, "source": ["**3. Training our linear NN model using SGD and the data provided by the previous step.**"]}, {"cell_type": "code", "metadata": {"id": "QDkUTG9ZV-nt", "colab_type": "code", "outputId": "995df867-c229-4b70-e328-f702f0882eb4", "executionInfo": {"status": "ok", "timestamp": 1579905264574, "user_tz": 480, "elapsed": 81929, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 176}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Adjust the training below to use a decaying learning rate / step size instead\n", "# of using a fixed rate of 0.01.\n", "# (Using a decaying learning rate is often a good idea to make quick progress in\n", "# the beginning but avoid making too big changes to already tuned parameters.)\n", "\n", "\n\n", "\n", "# Record values for loss and accuracy for plotting purposes.\n", "losses = []\n", "accs = []\n", "# Train for two epochs.\n", "epochs = 2\n", "for step, (x, y) in enumerate(dataset):\n", "  if step >= epochs * steps_per_epoch:\n", "    break\n", "  # Compute predictions from input and weights.\n", "  with tf.GradientTape() as tape:\n", "    logits = tf.matmul(tf.reshape(x, (x.shape[0], -1)), W) + b\n", "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, logits))\n", "  losses.append(loss.numpy())\n", "  W_grad, b_grad = tape.gradient(loss, (W, b))\n", "\n", "  # Gradient descent.\n", "  W.assign_add(-0.01 * W_grad)\n", "  b.assign_add(-0.01 * b_grad)\n", "\n", "  # Compute accuracy.\n", "  good_preds = tf.equal(tf.argmax(logits, axis=1), tf.argmax(y, axis=1))\n", "  acc = tf.reduce_mean(tf.cast(good_preds, tf.float32))\n", "  accs.append(acc.numpy())\n", "  # Prove we didn't freeze...\n", "  if step and step % 100 == 0:\n", "    print('step={:4d} loss={:2.3f} acc={:.3f}'.format(\n", "        step, np.mean(losses[-100:]), np.mean(accs[-100:])))"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "xRudDUpqx4dK", "colab_type": "code", "outputId": "e353216b-3128-4940-bf7b-a3a9ab897068", "executionInfo": {"status": "ok", "timestamp": 1579905264575, "user_tz": 480, "elapsed": 81921, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 264}}, "source": ["# Plot accuracy (should go up) and loss (should go down).\n", "# Note large variance from one batch to another.\n", "plt.plot(accs, 'g', label='accuracy')\n", "plt.legend(loc='upper right')\n", "plt.grid(False)\n", "plt.twinx().plot(losses, 'r', label='loss')\n", "plt.legend(loc='lower right')\n", "plt.grid(False)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "w-ELRwea7Qvl", "colab_type": "text"}, "source": ["## Keras, revisited"]}, {"cell_type": "markdown", "metadata": {"id": "04N8lmIZaYsk", "colab_type": "text"}, "source": ["### Models with custom layers\n", "\n", "In addition to using Keras in the simplified way as we've seen in `2_keras`,\n", "we can also customize specific layers.\n", "\n", "You might want to take a short look at: [TF guide - Keras Custom Layers](https://www.tensorflow.org/tutorials/customization/custom_layers)\n", "\n", "Particularly, this requires us to implement a class inheriting from `tf.keras.layers.Layer` and implementing the methods:\n", "\n", "1.   `build`\n", "2.   `call`\n", "3.   `compute_output_shape`\n", "4. (optional) `get_config` and `from_config` for layer serialization support"]}, {"cell_type": "code", "metadata": {"id": "JtAE88pF7SH6", "colab_type": "code", "colab": {}}, "source": ["class MyLinearLayer(tf.keras.layers.Layer):\n", "\n", "  def __init__(self, output_dim, **kwargs):\n", "    self.output_dim = output_dim\n", "    super().__init__(**kwargs)\n", "\n", "  # Define variables using `self.add_weight()` so Keras knows how to update\n", "  # weights.\n", "  def build(self, input_shape):\n", "    shape = tf.TensorShape((input_shape[1], self.output_dim))\n", "    self.W = self.add_weight(name='W',\n", "                             shape=shape,\n", "                             initializer='normal',\n", "                             trainable=True)\n", "    self.b = self.add_weight(name='b',\n", "                             shape=shape[1:],\n", "                             initializer='normal',\n", "                             trainable=True)\n", "    super().build(input_shape)\n", "\n", "  # Compute outputs from inputs (forward pass).\n", "  def call(self, inputs):\n", "    logits = tf.matmul(inputs, self.W) + self.b\n", "    return tf.nn.softmax(logits)\n", "\n", "  # Tell Keras how to verify shape conformity of layer stacking.\n", "  def compute_output_shape(self, input_shape):\n", "    shape = tf.TensorShape(input_shape).as_list()\n", "    shape[-1] = self.output_dim\n", "    return tf.TensorShape(shape)\n", "  \n", "  # Make layer work with model.get_config() and model.from_config().\n", "  def get_config(self):\n", "    base_config = super().get_config()\n", "    base_config['output_dim'] = self.output_dim\n", "    return base_config\n", "  \n", "  @classmethod\n", "  def from_config(cls, config):\n", "    return cls(**config)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "PmV7vx6deSSS", "colab_type": "text"}, "source": ["**Model definition**\n", "\n", "We can now define our TF model using `tf.keras.Sequential`."]}, {"cell_type": "code", "metadata": {"id": "mYSJOtfAnfeu", "colab_type": "code", "outputId": "1c5383b2-6e60-4a1f-9da9-1610140fd718", "executionInfo": {"status": "ok", "timestamp": 1579905264889, "user_tz": 480, "elapsed": 82218, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 230}}, "source": ["model = tf.keras.Sequential()\n", "model.add(tf.keras.layers.Flatten(input_shape=(64, 64,)))\n", "model.add(MyLinearLayer(len(labels)))\n", "\n", "model.compile(\n", "    optimizer='adam',\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy'])\n", "\n", "model.summary()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "XLi4Kn1yedB2", "colab_type": "text"}, "source": ["**Training the model**"]}, {"cell_type": "code", "metadata": {"id": "290Aujx7n6pp", "colab_type": "code", "outputId": "8daa99d9-2e3d-436d-94f8-2555ea2595d3", "executionInfo": {"status": "ok", "timestamp": 1579905270860, "user_tz": 480, "elapsed": 88180, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 70}}, "source": ["model.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=1)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "4et6U9VveluP", "colab_type": "text"}, "source": ["**Saving and loading a (trained) model**"]}, {"cell_type": "code", "metadata": {"id": "GUOoeyIV6a2a", "colab_type": "code", "colab": {}}, "source": ["# Note that the Keras serialized model contains weights and model parameters\n", "# but not the Python code for creating the layers!\n", "# If you save a model with a custom layer then you need to define the layer and\n", "# provide it to .load_model() as an argument so the model can be instantiated:\n", "model.save('./tmp.h5')\n", "loaded_model = tf.keras.models.load_model('./tmp.h5', \n", "                                          dict(MyLinearLayer=MyLinearLayer))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "ZSf4HKPUfrrT", "colab_type": "text"}, "source": ["### Training a bidirectional LSTM\n", "\n", "Instead of using the images directly, we can also utilize the stroke data in connection with a recurrent neural network.\n", "\n", "Particularly, we will train a bidirectional LSTM by going through the following steps:\n", "\n", "1. Data preparation\n", "2. Data inspection\n", "3. Model definition\n", "4. Model training"]}, {"cell_type": "markdown", "metadata": {"id": "SVXDO_1v5cgN", "colab_type": "text"}, "source": ["**1. Data preparation**\n", "\n", "The stroke data is available inside `TFRecord` files. Let's inspect the features\n", "of one example first."]}, {"cell_type": "code", "metadata": {"id": "tq_sI9b5RQnT", "colab_type": "code", "outputId": "efbe6016-2268-4081-8853-cefef8604037", "executionInfo": {"status": "ok", "timestamp": 1579905271460, "user_tz": 480, "elapsed": 88767, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 87}}, "source": ["data_path_stroke = data_path.replace('_img', '_stroke')\n", "tf_records_file = tf.io.gfile.glob('{}/train-*'.format(data_path_stroke))[0]\n", "print('One TFRecords file:\\n\\t{}'.format(tf_records_file))\n", "for record in tf.data.TFRecordDataset(tf.io.gfile.glob(\n", "    '{}/train-*'.format(data_path_stroke))[0]):\n", "  first_example = tf.train.Example.FromString(record.numpy())\n", "  break\n", "print('Features in example:\\n\\t{}'.format(\n", "    ' '.join(first_example.features.feature.keys())))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "hvyWkIGahwW-", "colab_type": "text"}, "source": ["Our recurrent neural network will expect dense tensors with fixed lengths. However, the different examples can have variable stroke lengths.\n", "\n", "**Note**: The QuickDraw stroke coordinate \"sparse tensors\" have a single dimension and do not contain any zeros at all.\n", "\n", "Let's define a helper function that:\n", "\n", "1.   Limits variable length sparse tensors to a maximum length.\n", "2.   Converts them to dense tensors."]}, {"cell_type": "code", "metadata": {"id": "RwjrgscDeagd", "colab_type": "code", "colab": {}}, "source": ["def convert_sparse(sparse, max_len):\n", "  \"\"\"Converts batched sparse tensor to dense tensor with specified size.\n", "\n", "  Args:\n", "    sparse: tf.SparseTensor instance of shape=[n].\n", "    max_len: Truncates / zero-pads the dense tensor to have a length equal to \n", "        this value.\n", "  \"\"\"\n", "  # Convert to dense tensor.\n", "  dense = tf.sparse.to_dense(sparse)\n", "  # Discard values above `max_len`.\n", "  dense = dense[:max_len]\n", "  # Zero-pad if length < `max_len`.\n", "  dense = tf.pad(dense, [[0, max_len - tf.shape(dense)[0]]])\n", "  return dense"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "W_mDsULDh81V", "colab_type": "text"}, "source": ["Let's look at an example to see how `convert_sparse()` works.\n", "\n", "We will use `stroke_x` as an example `tf.SparseTensor` with the X-coordinates `[1,2,3,4,5]`."]}, {"cell_type": "code", "metadata": {"id": "3HfxkupMem9O", "colab_type": "code", "outputId": "eed2c907-208b-4124-c2ad-0b3a6466dd92", "executionInfo": {"status": "ok", "timestamp": 1579905271461, "user_tz": 480, "elapsed": 88750, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 87}}, "source": ["stroke_x = tf.sparse.from_dense(tf.range(5))\n", "# Extract both shorter and longer dense tensors.\n", "dense_short = convert_sparse(stroke_x, max_len=3)\n", "dense_long = convert_sparse(stroke_x, max_len=10)\n", "print('Dense short (max_len=3):\\n\\t{}'.format(dense_short.numpy()))\n", "print('Dense long (max_len=10):\\n\\t{}'.format(dense_long.numpy()))"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "xihq2FQ6YqCG", "colab_type": "code", "outputId": "a8fe2d6c-c393-4c34-c305-37cf3cba7855", "executionInfo": {"status": "ok", "timestamp": 1579905272239, "user_tz": 480, "elapsed": 89518, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 87}}, "source": ["labels_stroke = [label.strip() for label in tf.io.gfile.GFile(\n", "    '{}/labels.txt'.format(data_path_stroke))]\n", "counts_stroke = json.load(tf.io.gfile.GFile(\n", "    '{}/counts.json'.format(data_path_stroke)))\n", "print('Labels({:d}):\\n\\t{}'.format(len(labels_stroke), labels_stroke))\n", "print('Counts:\\n\\t{}'.format(counts_stroke))"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "UC_5lflMfr1L", "colab_type": "code", "colab": {}}, "source": ["# Maximum number of points in concatenated strokes (exceeding discarded).\n", "MAX_LEN = 256\n", "\n", "# Because every drawing has a different number of points, we use `VarLenFeature`\n", "# and not `FixedLenFeature` for the stroke data. This will create a\n", "# `SparseTensor`.\n", "feature_spec_stroke = {\n", "    'stroke_x': tf.io.VarLenFeature(dtype=tf.float32),\n", "    'stroke_y': tf.io.VarLenFeature(dtype=tf.float32),\n", "    'stroke_z': tf.io.VarLenFeature(dtype=tf.float32),\n", "    'stroke_len': tf.io.FixedLenFeature([], tf.int64),\n", "    'label': tf.io.FixedLenFeature([], tf.int64),\n", "}\n", "\n", "def parse_example_stroke(serialized_example):\n", "  \"\"\"Parses a given tf.Example and creates a dense (limited) length tensor.\n", "\n", "  Args:\n", "    serialized_example: tf.Example to parse.\n", "  \"\"\"\n", "  features = tf.io.parse_single_example(serialized_example, feature_spec_stroke)\n", "  label = features.pop('label')\n", "\n", "  # We create a 'stroke' tensor with shape [3, MAX_LEN] where the first\n", "  # dimension indicates whether the values are X, Y, or Z coordinates.\n", "  stroke = tf.stack([\n", "      convert_sparse(features['stroke_x'], max_len=MAX_LEN),\n", "      convert_sparse(features['stroke_y'], max_len=MAX_LEN),\n", "      convert_sparse(features['stroke_z'], max_len=MAX_LEN),\n", "  ])\n", "  stroke = tf.transpose(stroke, perm=[1, 0])\n", "\n", "  # Also truncate the `stroke_len` to MAX_LEN if needed.\n", "  stroke_len = tf.minimum(tf.cast(MAX_LEN, tf.int64), features['stroke_len'])\n", "\n", "  return stroke, tf.one_hot(label, depth=len(labels_stroke))\n", "\n", "def make_ds_stroke(files_pattern, batch_size=100):\n", "  \"\"\"Converts all data within multiple TFRecord files into a\n", "     dense (limited) length tensor format, shuffles them and creates batches.\n", "\n", "  Args:\n", "    files_pattern: Path with the format `[...]/train-*`.\n", "    batch_size: Size to use for generating batches. \n", "  \"\"\"\n", "  dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(files_pattern))\n", "  dataset = dataset.map(parse_example_stroke).batch(batch_size)\n", "  dataset = dataset.shuffle(buffer_size=5*batch_size).repeat()\n", "  return dataset"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "SmwQ9m4kBA8a", "colab_type": "code", "colab": {}}, "source": ["# Adjust the batch size to the given hardware (#accelerators).\n", "batch_size = 100\n", "steps_per_epoch = counts_stroke['train'] // batch_size\n", "eval_steps_per_epoch = counts_stroke['eval'] // batch_size\n", "ds_stroke = make_ds_stroke('{}/train-*'.format(data_path_stroke), batch_size)\n", "ds_stroke_eval = make_ds_stroke('{}/eval-*'.format(data_path_stroke), \n", "                                batch_size)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "OgGy2F9z5ok9", "colab_type": "text"}, "source": ["**2. Data inspection**\n", "\n", "We can now use Matplotlib to visualize the stroke data."]}, {"cell_type": "code", "metadata": {"id": "PnjzYcWMdMLd", "colab_type": "code", "outputId": "42b21d95-3e1c-4816-9fc0-276886418041", "executionInfo": {"status": "ok", "timestamp": 1579905286649, "user_tz": 480, "elapsed": 103899, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 158}}, "source": ["from matplotlib import pyplot as plt\n", "\n", "def show_stroke_img(stroke, label, ax=None):\n", "  \"\"\"Plots stroke data.\n", "\n", "  Args:\n", "    stroke: Array of shape=[3, n] where the second dimension\n", "        is time and the first dimension indicates X/Y coordinates\n", "        and Z-dimension that is set to 1 when a stroke ends and\n", "        0 otherwise (the array actually represents an array of\n", "        concatenated strokes and the Z-dimension is needed to tell\n", "        the individual strokes apart).\n", "  \"\"\"\n", "  ax = ax if ax else plt.gca()\n", "  xy = stroke[:2, :].cumsum(axis=1)\n", "  ax.plot(xy[0, :], -xy[1, :])\n", "  # Plot all the strokes, including connecting line between strokes.\n", "  pxy = xy[:, stroke[2] != 0]\n", "  # Red dots mark end of individual strokes.\n", "  ax.plot(pxy[0], -pxy[1], 'ro')\n", "  ax.set_xticks([])\n", "  ax.set_yticks([])\n", "  ax.set_title(label)\n", "\n", "# Load a single batch of images:\n", "for x, y in ds_stroke:\n", "  break\n", "\n", "# Plot some images\n", "plt.figure(figsize=(10, 2))\n", "for i in range(5):\n", "  ax = plt.subplot(1, 5, i+1)\n", "  show_stroke_img(x[i].numpy().T, labels_stroke[y[i].numpy().argmax()], ax)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "CPjiA4Ne59j8", "colab_type": "text"}, "source": ["**3. Model definition**\n", "\n", "While defining a linear model using basic TensorFlow operations was quite easy, defining a bidirectional LSTM would be a nightmare!\n", "\n", "Luckily Keras provides us with good implementations of many common network components and putting these together requires only a few lines of code:"]}, {"cell_type": "code", "metadata": {"id": "AN22HwgRqcrs", "colab_type": "code", "outputId": "c6147f48-8e0f-43c3-c8a7-b455d64b7b41", "executionInfo": {"status": "ok", "timestamp": 1579905287840, "user_tz": 480, "elapsed": 105075, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 265}}, "source": ["lstm_model = tf.keras.Sequential()\n", "\n", "# Masking means that we don't do computations on all the `0` used for padding\n", "# of sequences shorter than MAX_LEN.\n", "# While masking is not strictly needed it makes learning a lot faster.\n", "lstm_model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(MAX_LEN, 3)))\n", "lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256), \n", "                                            input_shape=(MAX_LEN, 3)))\n", "\n", "lstm_model.add(tf.keras.layers.Dense(len(labels_stroke), activation='softmax'))\n", "\n", "lstm_model.compile(\n", "    optimizer=tf.keras.optimizers.Adam(0.01),\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy', tf.keras.metrics.categorical_accuracy])\n", "\n", "lstm_model.summary()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "YkW7lhU86BdH", "colab_type": "text"}, "source": ["**4. Training the model**\n"]}, {"cell_type": "code", "metadata": {"id": "AYSQDHIyaNMG", "colab_type": "code", "outputId": "d9498241-985f-4e60-dc8b-addcd71e1c62", "executionInfo": {"status": "ok", "timestamp": 1579905618973, "user_tz": 480, "elapsed": 436198, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 87}}, "source": ["# This is a pretty heavy model. If you train on CPU you probably want to reduce\n", "# the number of steps.\n", "lstm_model.fit(ds_stroke, steps_per_epoch=steps_per_epoch, epochs=1)\n", "lstm_model.evaluate(ds_stroke_eval, steps=eval_steps_per_epoch)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "grr29b3-gCd-", "colab_type": "text"}, "source": ["# ----- Optional part -----"]}, {"cell_type": "markdown", "metadata": {"id": "yIUGFX2puKkT", "colab_type": "text"}, "source": ["## TensorBoard\n", "\n", "TensorBoard is a great tool to observe variables during training (especially useful for models training a long time, like above LSTM)."]}, {"cell_type": "code", "metadata": {"id": "ksy0-ftJflXV", "colab_type": "code", "outputId": "f4d466b2-6405-4c77-e633-3c3295274206", "executionInfo": {"status": "ok", "timestamp": 1579905618974, "user_tz": 480, "elapsed": 436186, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["import datetime\n", "now = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n", "tensorboard_path = './tensorboard/lstm_{}'.format(now)\n", "os.makedirs(tensorboard_path)\n", "tensorboard_path"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "9cbs06JH-AHO", "colab_type": "code", "colab": {}}, "source": ["# This callback will make Keras record loss and metrics.\n", "callbacks = [\n", "    tf.keras.callbacks.TensorBoard(\n", "        log_dir=tensorboard_path, update_freq='batch'),\n", "]"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "AtQK94qsJgLC", "colab_type": "code", "colab": {}}, "source": ["def get_stroke_lengths(strokes):\n", "  \"\"\"Returns the length of a batch of strokes.\n", "\n", "  Args:\n", "    strokes : Dense Tensor with shape `[batch_size, max_length, 3]` that is zero\n", "        padded in the second dimension.\n", "\n", "  Returns:\n", "    Vector of stroke lengths (=number of elements in the second dimension that\n", "        are non-zero).\n", "  \"\"\"\n", "  batch_size, max_length = strokes.shape.as_list()[:2]\n", "\n", "  # nonzero.shape = [batch_size, max_length] with `True` for every non-zero\n", "  # element.\n", "  nonzero = tf.greater(\n", "      tf.reduce_sum(tf.cast(tf.greater(strokes, 0), tf.float32), axis=2), 0)\n", "  \n", "  # Return the index of the right-most non-zero element.\n", "  return max_length - tf.argmax(tf.cast(nonzero, tf.float32)[:,::-1], axis=1)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "UWOSGJhRhbtf", "colab_type": "code", "outputId": "a566e25c-167f-4650-b930-8f413c97c340", "executionInfo": {"status": "ok", "timestamp": 1579905625451, "user_tz": 480, "elapsed": 442609, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 264}}, "source": ["# Check out the stroke length of the first batch.\n", "for x, y in ds_stroke:\n", "  break\n", "plt.hist(get_stroke_lengths(x));"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "vT2ZD4EUEs-2", "colab_type": "code", "colab": {}}, "source": ["class SummaryRecorder(tf.keras.layers.Layer):\n", "  \"\"\"A layer that records strokes lengths with `tf.summary`.\"\"\"\n", "\n", "  def __init__(self, optimizer, **kwargs):\n", "    self.optimizer = optimizer\n", "    super().__init__(**kwargs)\n", "\n", "  def get_config(self):\n", "    return dict(optimizer=self.optimizer)\n", "\n", "  def call(self, strokes):\n", "    stroke_lengths = get_stroke_lengths(strokes)\n", "    step = self.optimizer.iterations\n", "    tf.summary.scalar(\n", "        name='avg_stroke_length', data=tf.reduce_mean(stroke_lengths),\n", "        step=step)\n", "    tf.summary.histogram(\n", "        name='stroke_lengths', data=stroke_lengths, step=step)\n", "    return strokes"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "TYOetgwu1fcG", "colab_type": "code", "outputId": "0461d525-000f-49b5-cb95-1dda1bb2a584", "executionInfo": {"status": "ok", "timestamp": 1579905627328, "user_tz": 480, "elapsed": 444461, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 301}}, "source": ["# Code copied from section \"Training a bidirectional LSTM\", but with an\n", "# additional Lambda layer for the recording of the stroke lengths:\n", "optimizer = tf.keras.optimizers.Adam(0.05)\n", "\n", "lstm_model = tf.keras.Sequential()\n", "lstm_model.add(SummaryRecorder(optimizer, input_shape=(MAX_LEN, 3)))\n", "lstm_model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(MAX_LEN, 3)))\n", "lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256)))\n", "lstm_model.add(tf.keras.layers.Dense(len(labels_stroke), activation='softmax'))\n", "\n", "lstm_model.compile(\n", "    optimizer=optimizer,\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy', tf.keras.metrics.categorical_accuracy])\n", "\n", "lstm_model.summary()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "Z329SZSAZiWO", "colab_type": "code", "colab": {}}, "source": ["# Forwarding of TensorBoard's 6006 port using https://ngrok.com\n", "\n", "# Download & unzip ngrok\n", "!if [ ! -f ngrok ]; then \\\n", " wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip; \\\n", " unzip -o ngrok-stable-linux-amd64.zip; \\\n", " fi\n", "\n", "# Start TensorBoard\n", "!pkill tensorboard\n", "get_ipython().system_raw(\n", "    'tensorboard --reload_interval 0 --logdir ./tensorboard --port 6006 &'\n", ")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "ZVDSMw9px81g", "colab_type": "code", "outputId": "0210061b-2c82-490a-b911-f605ca7287c4", "executionInfo": {"status": "ok", "timestamp": 1579906258255, "user_tz": 480, "elapsed": 8350, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Open a new ngrok tunnel. Re-execute this cell if you run into quota issues\n", "# (\"Too many connections\").\n", "\n", "!pkill ngrok\n", "# Forward port.\n", "get_ipython().system_raw('./ngrok http 6006 &')\n", "# Give some time to start up.\n", "!sleep 1\n", "# Output external address (ngrok's web interface listens at 4004).\n", "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "-USh58Jp-_zD", "colab_type": "text"}, "source": ["Open TensorBoard in a seaprate tab by clicking on the above link."]}, {"cell_type": "code", "metadata": {"id": "aejIJicUT8YB", "colab_type": "code", "outputId": "f9103df3-7ea3-4850-cc18-58d6841a9000", "executionInfo": {"status": "ok", "timestamp": 1579905937761, "user_tz": 480, "elapsed": 754876, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 52}}, "source": ["# Summary writers store information logged via `tf.summary.*` to disk for\n", "# inspection by TensorBoard.\n", "summary_writer = tf.summary.create_file_writer(\n", "    os.path.join(tensorboard_path, 'strokes'), flush_millis=1000)\n", "\n", "# Then let's create a new model and train it again.\n", "# Check out TensorBoard during training (click on the \"refresh\" button to see\n", "# new data).\n", "with summary_writer.as_default():\n", "  history = lstm_model.fit(\n", "      ds_stroke, steps_per_epoch=steps_per_epoch, epochs=1, callbacks=callbacks)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "6H9c7uDLi45c", "colab_type": "code", "outputId": "06e324ba-ef74-49ac-b547-b6d427544bb8", "executionInfo": {"status": "ok", "timestamp": 1579905939765, "user_tz": 480, "elapsed": 756874, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 212}}, "source": ["# Summaries are stored as \"events.out.tfevents.*\" files.\n", "!find ./tensorboard"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "kMXOYejJ2ylo", "colab_type": "code", "colab": {}}, "source": ["# YOUR ACTION REQUIRED:\n", "# How does the accuracy develop over time? You can rerun the training cell to\n", "# train more epochs and append more data to the summaries.\n", "# You can also define new models with different parameters (optimizer learning\n", "# rate, cell size, ...) and compare model performance in TensorBoard. Rerun the\n", "# cell that defines tensorboard_path to store the summaries in different\n", "# directories."], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "MFNVbjjlAGO7", "colab_type": "text"}, "source": ["## TPU Support\n", "\n", "As we did in the previous notebook, we'll need to do some adjustments to train our models on a TPU (works only on Colab).\n", "\n", "> **Attention:** Please make sure to switch the runtime to TPU for this part. You can do so via: \"Runtime > Change runtime type > Hardware Accelerator\" in Colab. As this might create a new environment this section can be executed isolated from anything above."]}, {"cell_type": "code", "metadata": {"id": "DaJT2rNZFpgQ", "colab_type": "code", "colab": {"base_uri": "https://localhost:8080/", "height": 34}, "outputId": "d49a0196-e379-4c1c-9a54-b31970ddd97f", "executionInfo": {"status": "ok", "timestamp": 1579906053688, "user_tz": 480, "elapsed": 30480, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}}, "source": ["%tensorflow_version 2.x"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "89dqMmDmFqBx", "colab_type": "code", "outputId": "8e3e3330-bd25-44cd-94ad-5193e51caf6b", "executionInfo": {"status": "ok", "timestamp": 1579906073473, "user_tz": 480, "elapsed": 50257, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 425}}, "source": ["import json, os\n", "import numpy as np\n", "from matplotlib import pyplot as plt\n", "import tensorflow as tf\n", "\n", "# Disable duplicate logging output in TF.\n", "logger = tf.get_logger()\n", "logger.propagate = False\n", "\n", "# This will fail if no TPU is connected...\n", "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n", "# Set up distribution strategy.\n", "tf.config.experimental_connect_to_cluster(tpu)\n", "tf.tpu.experimental.initialize_tpu_system(tpu);\n", "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n", "\n", "# Tested with TensorFlow 2.1.0\n", "print('\\n\\nTF version={} TPUs={} accelerators={}'.format(\n", "    tf.__version__, tpu.cluster_spec().as_dict()['worker'],\n", "    strategy.num_replicas_in_sync))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "liv2SeFnXerM", "colab_type": "text"}, "source": ["> **Attention:** TPUs require all files (input and models) to be stored in cloud storage buckets (`gs://bucket-name/...`). If you plan to use TPUs please choose the `data_path` below accordingly. Otherwise, you might run into `File system scheme '[local]' not implemented` errors."]}, {"cell_type": "code", "metadata": {"id": "KcMwdgHPA1bx", "colab_type": "code", "colab": {}}, "source": ["from google.colab import auth\n", "auth.authenticate_user()\n", "\n", "# Browse datasets:\n", "# https://console.cloud.google.com/storage/browser/amld-datasets\n", "\n", "# - 50k training examples, including pickled DataFrame.\n", "data_path_stroke = 'gs://amld-datasets/zoo_stroke_small'\n", "# - 1M training examples, without pickled DataFrame.\n", "# data_path_stroke = 'gs://amld-datasets/zoo_stroke'\n", "# - 4.1M training examples, without pickled DataFrame.\n", "# data_path_stroke = 'gs://amld-datasets/animals_stroke'\n", "# - 29M training examples, without pickled DataFrame.\n", "# data_path_stroke = 'gs://amld-datasets/all_stroke'"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "nZLuuaY72RxT", "colab_type": "code", "cellView": "form", "colab": {"base_uri": "https://localhost:8080/", "height": 158}, "outputId": "32f3bb9b-c01a-41c7-84ea-2bf8c457c31e", "executionInfo": {"status": "ok", "timestamp": 1579906097364, "user_tz": 480, "elapsed": 74133, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}}, "source": ["#@markdown **Copied and adjusted data definition code from above**\n", "#@markdown\n", "#@markdown &nbsp;&nbsp; Note: You can double-click this cell to see its code.\n", "#@markdown\n", "#@markdown The changes have been highlighted with `!` in the contained code\n", "#@markdown (things like the `batch_size` and added `drop_remainder=True`).\n", "#@markdown\n", "#@markdown Feel free to just **click \"execute\"** and ignore the details for now.\n", "\n", "tf_records_file = tf.io.gfile.glob('{}/train-*'.format(data_path_stroke))[0]\n", "print('One TFRecords file:\\n\\t{}'.format(tf_records_file))\n", "for record in tf.data.TFRecordDataset(tf.io.gfile.glob(\n", "    '{}/train-*'.format(data_path_stroke))[0]):\n", "  first_example = tf.train.Example.FromString(record.numpy())\n", "  break\n", "print('Features in example:\\n\\t{}'.format(\n", "    ' '.join(first_example.features.feature.keys())))\n", "\n", "def convert_sparse(sparse, max_len):\n", "  \"\"\"Converts batched sparse tensor to dense tensor with specified size.\n", "\n", "  Args:\n", "    sparse: tf.SparseTensor instance of shape=[n].\n", "    max_len: Truncates / zero-pads the dense tensor to have a length equal to \n", "        this value.\n", "  \"\"\"\n", "  # Convert to dense tensor.\n", "  dense = tf.sparse.to_dense(sparse)\n", "  # Discard values above `max_len`.\n", "  dense = dense[:max_len]\n", "  # Zero-pad if length < `max_len`.\n", "  dense = tf.pad(dense, [[0, max_len - tf.shape(dense)[0]]])\n", "  # TPU does not support dynamic shapes.\n", "  dense = tf.reshape(dense, [max_len])\n", "  # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n", "  return dense\n", "\n", "labels_stroke = [label.strip() for label in tf.io.gfile.GFile(\n", "    '{}/labels.txt'.format(data_path_stroke))]\n", "counts_stroke = json.load(tf.io.gfile.GFile(\n", "    '{}/counts.json'.format(data_path_stroke)))\n", "print('Labels({:d}):\\n\\t{}'.format(len(labels_stroke), labels_stroke))\n", "print('Counts:\\n\\t{}'.format(counts_stroke))\n", "\n", "# Maximum number of points in concatenated strokes (exceeding discarded).\n", "MAX_LEN = 256\n", "\n", "# Because every drawing has a different number of points, we use `VarLenFeature`\n", "# and not `FixedLenFeature` for the stroke data. This will create a\n", "# `SparseTensor`.\n", "feature_spec_stroke = {\n", "    'stroke_x': tf.io.VarLenFeature(dtype=tf.float32),\n", "    'stroke_y': tf.io.VarLenFeature(dtype=tf.float32),\n", "    'stroke_z': tf.io.VarLenFeature(dtype=tf.float32),\n", "    'stroke_len': tf.io.FixedLenFeature([], tf.int64),\n", "    'label': tf.io.FixedLenFeature([], tf.int64),\n", "}\n", "\n", "def parse_example_stroke(serialized_example):\n", "  \"\"\"Parses a given tf.Example and creates a dense (limited) length tensor.\n", "\n", "  Args:\n", "    serialized_example: tf.Example to parse.\n", "  \"\"\"\n", "  features = tf.io.parse_single_example(serialized_example, feature_spec_stroke)\n", "  label = features.pop('label')\n", "\n", "  # We create a 'stroke' tensor with shape [3, MAX_LEN] where the first\n", "  # dimension indicates whether the values are X, Y, or Z coordinates.\n", "  stroke = tf.stack([\n", "      convert_sparse(features['stroke_x'], max_len=MAX_LEN),\n", "      convert_sparse(features['stroke_y'], max_len=MAX_LEN),\n", "      convert_sparse(features['stroke_z'], max_len=MAX_LEN),\n", "  ])\n", "  stroke = tf.transpose(stroke, perm=[1, 0])\n", "\n", "  # Also truncate the `stroke_len` to MAX_LEN if needed.\n", "  stroke_len = tf.minimum(tf.cast(MAX_LEN, tf.int64), features['stroke_len'])\n", "\n", "  return stroke, tf.one_hot(label, depth=len(labels_stroke))\n", "\n", "def make_ds_stroke(files_pattern, batch_size=100):\n", "  \"\"\"Converts all data within multiple TFRecord files into a\n", "     dense (limited) length tensor format, shuffles them and creates batches.\n", "\n", "  Args:\n", "    files_pattern: Path with the format `[...]/train-*`.\n", "    batch_size: Size to use for generating batches. \n", "  \"\"\"\n", "  dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(files_pattern))\n", "  dataset = dataset.map(parse_example_stroke).batch(batch_size, drop_remainder=True)\n", "  dataset = dataset.shuffle(buffer_size=5*batch_size).repeat()\n", "  return dataset\n", "\n", "# Adjust the batch size to the given hardware (#accelerators).\n", "batch_size = 64 * strategy.num_replicas_in_sync\n", "#            !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n", "steps_per_epoch = counts_stroke['train'] // batch_size\n", "eval_steps_per_epoch = counts_stroke['eval'] // batch_size\n", "ds_stroke = make_ds_stroke('{}/train-*'.format(data_path_stroke), batch_size)\n", "ds_stroke_eval = make_ds_stroke('{}/eval-*'.format(data_path_stroke), \n", "                                batch_size)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "HnFqN8S0DZUj", "colab_type": "code", "colab": {"base_uri": "https://localhost:8080/", "height": 265}, "outputId": "ace773ae-6ef0-4f62-f20d-ab9e18d95c24", "executionInfo": {"status": "ok", "timestamp": 1579906100559, "user_tz": 480, "elapsed": 77323, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}}, "source": ["# Model definition code needs to be wrapped in scope.\n", "with strategy.scope():\n", "  lstm_model = tf.keras.Sequential()\n", "  lstm_model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(MAX_LEN, 3)))\n", "  lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256), \n", "                                              input_shape=(MAX_LEN, 3)))\n", "  lstm_model.add(tf.keras.layers.Dense(len(labels_stroke), activation='softmax'))\n", "\n", "lstm_model.compile(\n", "    optimizer=tf.keras.optimizers.Adam(0.01),\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy', tf.keras.metrics.categorical_accuracy])\n", "lstm_model.summary()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "uKvxEPMMEIvc", "colab_type": "code", "colab": {"base_uri": "https://localhost:8080/", "height": 425}, "outputId": "96c2e4c8-5b96-409f-f9de-f2bee46ef7b7", "executionInfo": {"status": "ok", "timestamp": 1579906197435, "user_tz": 480, "elapsed": 174192, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}}, "source": ["# Note the massive speedup (compared to above, we train 10x more) !\n", "lstm_model.fit(ds_stroke, steps_per_epoch=steps_per_epoch, epochs=10)\n", "lstm_model.evaluate(ds_stroke_eval, steps=eval_steps_per_epoch)"], "execution_count": null, "outputs": []}]}