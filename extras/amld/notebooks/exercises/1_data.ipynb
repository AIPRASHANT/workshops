{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"name": "1_data", "provenance": [{"file_id": "https://github.com/tensorflow/workshops/blob/master/extras/amld/notebooks/solutions/1_qd_data.ipynb", "timestamp": 1544434140243}], "collapsed_sections": [], "toc_visible": true}, "kernelspec": {"name": "python3", "display_name": "Python 3"}}, "cells": [{"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "rtiYQNdwGeFs"}, "source": ["# QuickDraw Data\n", "\n", "If machine learning is rocket science then data is your fuel! So before\n", "doing anything we will have a close look at the data available and spend\n", "some time bringing it into the \"right\" form (i.e.\n", "[tf.train.Example](https://www.tensorflow.org/api_docs/python/tf/train/Example)).\n", "\n", "That's why we start by spending quite a lot of time on this notebook, downloading\n", "the data, understanding it, and transforming it into the right format for\n", "Tensorflow.\n", "\n", "The data used in this workshop is taken from Google's quickdraw (click on\n", "the images to see loads of examples):\n", "\n", "https://quickdraw.withgoogle.com/data\n", "\n", "We will download the data below."]}, {"cell_type": "markdown", "metadata": {"id": "wLhwRewZcVl8", "colab_type": "text"}, "source": ["## Init"]}, {"cell_type": "markdown", "metadata": {"id": "Sv44gRqoyCBi", "colab_type": "text"}, "source": ["First, we'll choose where our data should be stored.\n", "\n", "If you choose a path under **\"/content/gdrive/My Drive\"** then data will be stored in your Google drive and persisted across VM starts (preferable)."]}, {"cell_type": "code", "metadata": {"id": "twZEazVEiS4W", "colab_type": "code", "colab": {}}, "source": ["data_path = '/content/gdrive/My Drive/amld_data'\n", "# Alternatively, you can also store the data in a local directory. This method\n", "# will also work when running the notebook in Jupyter instead of Colab.\n", "# data_path = './amld_data"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "HPH_5nWRfTfH", "colab_type": "code", "outputId": "a2c5e9a5-0f21-439f-a9b4-b98e2cf25f57", "executionInfo": {"status": "ok", "timestamp": 1579992695967, "user_tz": 480, "elapsed": 58597, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 125}}, "source": ["if data_path.startswith('/content/gdrive/'):\n", "  from google.colab import drive\n", "  assert data_path.startswith('/content/gdrive/My Drive/'), 'Google Drive paths must start with \"/content/gdrive/My Drive/\"!'\n", "  drive.mount('/content/gdrive')\n", "\n", "if data_path.startswith('gs://'):\n", "  from google.colab import auth\n", "  auth.authenticate_user()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "54oWbpOKxU6u", "colab_type": "code", "outputId": "bafcd453-9c5b-4c1e-8b6a-aaa4ee76edc1", "executionInfo": {"status": "ok", "timestamp": 1579992695968, "user_tz": 480, "elapsed": 58595, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# In Jupyter, you would need to install TF 2 via !pip.\n", "%tensorflow_version 2.x"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "3vi-RvO1w0VJ", "colab_type": "code", "outputId": "1c95fdd6-cd19-419d-f1b1-d69e5d3b9ab0", "executionInfo": {"status": "ok", "timestamp": 1579992703239, "user_tz": 480, "elapsed": 65863, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Always make sure you are using running the expected version.\n", "# There are considerable differences between versions.\n", "# This Colab was tested with 2.1.0.\n", "import tensorflow as tf\n", "tf.__version__"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "EBkp94O9GeFt", "colab": {}}, "source": ["import base64, collections, io, itertools, functools, json, os, random, re, textwrap, time, urllib, xml\n", "\n", "import numpy as np\n", "import pandas as pd\n", "from matplotlib import pyplot as plt\n", "from PIL import Image, ImageDraw\n", "from IPython import display"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "eY81Xe9CGeFz"}, "source": ["## Get the data\n", "\n", "In this section we download a set of raw data files from the web."]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "ujcwY2WRGeFz", "outputId": "48ebfa1f-d2b0-4a56-f7fc-50d91a396fdd", "executionInfo": {"status": "ok", "timestamp": 1579992703240, "user_tz": 480, "elapsed": 65859, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 550}}, "source": ["# Retrieve list of categories.\n", "\n", "def list_bucket(bucket, regexp='.*'):\n", "    \"\"\"Returns a filtered list of Keys in specified GCS bucket.\"\"\"\n", "    keys = []\n", "    fh = urllib.request.urlopen('https://storage.googleapis.com/%s' % bucket)\n", "    content = xml.dom.minidom.parseString(fh.read())\n", "    for e in content.getElementsByTagName('Contents'):\n", "        key = e.getElementsByTagName('Key')[0].firstChild.data\n", "        if re.match(regexp, key):\n", "            keys.append(key)\n", "    return keys\n", "\n", "all_ndjsons = list_bucket('quickdraw_dataset', '.*ndjson$')\n", "print('available: (%d)' % len(all_ndjsons))\n", "print('\\n'.join(textwrap.wrap(\n", "    '|'.join([key.split('/')[-1].split('.')[0] for key in all_ndjsons]),\n", "    width=100)))"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "MjaUHJ7zGeF3", "colab": {}}, "source": ["# Mini group of two animals.\n", "pets = ['cat', 'dog']\n", "\n", "# Somewhat larger group of zoo animals.\n", "zoo = ['camel', 'crocodile', 'dolphin', 'elephant', 'flamingo', 'giraffe',\n", "       'kangaroo', 'lion', 'monkey', 'penguin', 'rhinoceros']\n", "\n", "# Even larger group of all animals.\n", "animals = ['ant', 'bat', 'bear', 'bee', 'bird', 'butterfly', 'camel', 'cat',\n", "           'cow', 'crab', 'crocodile', 'dog', 'dolphin', 'dragon', 'duck',\n", "           'elephant', 'fish', 'flamingo', 'frog', 'giraffe', 'hedgehog',\n", "           'horse', 'kangaroo', 'lion', 'lobster', 'monkey', 'mosquito',\n", "           'mouse', 'octopus', 'owl', 'panda', 'parrot', 'penguin', 'pig',\n", "           'rabbit', 'raccoon', 'rhinoceros', 'scorpion', 'sea turtle', 'shark',\n", "           'sheep', 'snail', 'snake', 'spider', 'squirrel', 'swan']\n", "\n", "# You could do something like:\n", "# my_objects = ['shoe', 'shorts', 't-shirt']"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "6Df5Br4Pyb9b", "colab_type": "text"}, "source": ["Create your own group -- the more categories you include the more challenging the classification task will be..."]}, {"cell_type": "code", "metadata": {"id": "V-wVsOV4yZlA", "colab_type": "code", "colab": {}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Choose one of above groups for remainder of workshop.\n", "# Note: This will result in ~100MB of download per class.\n", "# `dataset_name` will be used to construct directories containing the data.\n", "labels, dataset_name = zoo, 'zoo'\n", "\n", "# Or use another dataset defined above:\n", "# labels, dataset_name = pets, 'pets'\n", "# labels, dataset_name = animals, 'animals'"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "tmzXx5skGeF5", "outputId": "9ca0694e-3540-451e-9561-17ca7f1e001f", "executionInfo": {"status": "ok", "timestamp": 1579992733183, "user_tz": 480, "elapsed": 95794, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 674}}, "source": ["# Download above chosen group.\n", "\n", "def valid_ndjson(filename):\n", "  \"\"\"Checks presence + completeness of .ndjson file.\"\"\"\n", "  try:\n", "    json.loads(tf.io.gfile.GFile(filename).readlines()[-1])\n", "    return True\n", "  except (ValueError, IOError):\n", "    return False\n", "\n", "def retrieve(bucket, key, filename):\n", "  \"\"\"Returns a file specified by its Key from a GCS bucket.\"\"\"\n", "  url = 'https://storage.googleapis.com/%s/%s' % (\n", "    bucket, urllib.parse.quote(key))\n", "  print('\\n' + url)\n", "  if not tf.io.gfile.exists(filename):\n", "    with tf.io.gfile.GFile(filename, 'w') as f:\n", "      f.write(urllib.request.urlopen(url).read())\n", "  while not valid_ndjson(filename):\n", "    print('*** Corrupted download (%.2f MB), retrying...' % (\n", "        os.path.getsize(filename) / 2.**20))\n", "    with tf.io.gfile.GFile(filename, 'w') as f:\n", "      f.write(urllib.request.urlopen(url).read())\n", "\n", "tf.io.gfile.makedirs(data_path)\n", "\n", "print('\\n%d labels:' % len(labels))\n", "\n", "for name in labels:\n", "  print(name, end=' ')\n", "  dst = '%s/%s.ndjson' % (data_path, name)\n", "  retrieve('quickdraw_dataset', 'full/simplified/%s.ndjson' % name, dst)\n", "  print('%.2f MB' % (tf.io.gfile.stat(dst).length / 2.**20))\n", "\n", "print('\\nDONE :)')"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "ZO6tp_h-GeF8"}, "source": ["## Inspect the data\n", "\n", "Let's find out what the format of the downloaded files is.\n", "\n", "First, we are going to enumerate them."]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "Xb_2LxbMGeF_", "outputId": "a648a17f-e9b0-4248-a093-8d750249bc4d", "executionInfo": {"status": "ok", "timestamp": 1579992735447, "user_tz": 480, "elapsed": 98055, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 265}}, "source": ["print('\\n'.join([\n", "                 '%6.1fM : %s' % (tf.io.gfile.stat(path).length/1024**2, path)\n", "                 for path in tf.io.gfile.glob('{}/*.ndjson'.format(data_path))\n", "                 ]))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "HBz4Bn90yyWX", "colab_type": "text"}, "source": ["Let's further explore what the `NDJSON` file format is."]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "UCL46qhKGeGC", "outputId": "d14b5f96-2380-4a78-a624-ea00322395f2", "executionInfo": {"status": "ok", "timestamp": 1579992735629, "user_tz": 480, "elapsed": 98234, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 90}}, "source": ["path = sorted(tf.io.gfile.glob(os.path.join(data_path, '*.ndjson')))[0]\n", "print(path)\n", "print(tf.io.gfile.GFile(path).read()[:1000] + '...')"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "tAVekUf8y7dx", "colab_type": "text"}, "source": ["As we can see, it's a format that contains one JSON dictionary per line.\n", "\n", "Let's parse one single line."]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "f6m9rZzjGeGG", "outputId": "f9ef9f3f-829a-4381-9d72-bcc76a2e9364", "executionInfo": {"status": "ok", "timestamp": 1579992735630, "user_tz": 480, "elapsed": 98232, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["data_json = json.loads(tf.io.gfile.GFile(path).readline())\n", "data_json.keys()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "XKyZ2P4KGeGJ", "outputId": "7a0ab7c2-d272-44a2-aebc-9611b23f4551", "executionInfo": {"status": "ok", "timestamp": 1579992735630, "user_tz": 480, "elapsed": 98230, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 105}}, "source": ["# So we have some meta information.\n", "for k, v in data_json.items():\n", "  if k != 'drawing':\n", "    print('%20s   ->   %s' % (k, v))"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "S8uCmlQ_GeGN", "outputId": "1f7a50ec-727a-4057-eec8-aae0d0c4d265", "executionInfo": {"status": "ok", "timestamp": 1579992735631, "user_tz": 480, "elapsed": 98228, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 52}}, "source": ["# Extract the actual drawing.\n", "drawing = data_json['drawing']\n", "\n", "# The drawing consists of a series of strokes:\n", "print('Shapes:', [np.array(stroke).shape for stroke in drawing])\n", "print('Example stroke:', drawing[0])"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "bb7XhpB4GeGQ", "outputId": "ae1892cb-3b62-4f75-fad4-14ede247e7e2", "executionInfo": {"status": "ok", "timestamp": 1579992736037, "user_tz": 480, "elapsed": 98632, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 264}}, "source": ["# Draw the image -- the strokes all have have shape (2, n)\n", "# so the first index seems to be x/y coordinate:\n", "for stroke in drawing:\n", "  # Each array has X coordinates at [0, :] and Y coordinates at [1, :].\n", "  plt.plot(np.array(stroke[0]), -np.array(stroke[1]))\n", "# Would YOU recognize this drawing successfully?"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "1wwxryjLGeGU", "outputId": "c4388c44-3b20-434b-b157-d9361315832c", "executionInfo": {"status": "ok", "timestamp": 1579992736038, "user_tz": 480, "elapsed": 98630, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Some more code to load many sketches at once.\n", "# Let's ignore the difficult `unrecognized` sketches for now\n", "# (i.e. unrecognized by the official quickdraw classifier).\n", "\n", "def convert(line):\n", "  \"\"\"Converts single JSON line and converts 'drawing' to list of np.array.\"\"\"\n", "  d = json.loads(line)\n", "  d['drawing'] = [np.array(stroke) for stroke in d['drawing']]\n", "  return d\n", "\n", "def loaditer(name, unrecognized=False):\n", "  \"\"\"Returns iterable of drawings in specified file.\n", "\n", "  Args:\n", "    name: Name of the downloaded object (e.g. \"elephant\").\n", "    unrecognized: Whether to include drawings that were not recognized\n", "        by Google AI (i.e. the hard ones).\n", "  \"\"\"\n", "  for line in tf.io.gfile.GFile('%s/%s.ndjson' % (data_path, name)):\n", "    d = convert(line)  \n", "    if d['recognized'] or unrecognized:\n", "      yield d\n", "\n", "def loadn(name, n, unrecognized=False):\n", "  \"\"\"Returns list of drawings.\n", "  \n", "  Args:\n", "    name: Name of the downloaded object (e.g. \"elephant\").\n", "    n: Number of drawings to load.\n", "    unrecognized: Whether to include drawings that were not recognized\n", "        by Google AI (i.e. the hard ones).\n", "  \"\"\"\n", "  it = loaditer(name, unrecognized=unrecognized)\n", "  return list(itertools.islice(it, 0, n))\n", "\n", "n = 100\n", "print('Loading {} instances of \"{}\"...'.format(n, labels[0]), end='')\n", "sample = loadn(labels[0], 100)\n", "print('done.')"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "-jzTKBt5GeGY", "outputId": "d056d54c-f32d-4513-8923-24ec936dcdbd", "executionInfo": {"status": "ok", "timestamp": 1579992737298, "user_tz": 480, "elapsed": 99886, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 536}}, "source": ["# Some more drawings.\n", "rows, cols = 3, 3\n", "plt.figure(figsize=(3*cols, 3*rows))\n", "for y in range(rows):\n", "  for x in range(cols):\n", "    i = y * cols + x\n", "    plt.subplot(rows, cols, i + 1)\n", "    for stroke in sample[i]['drawing']:\n", "      plt.plot(np.array(stroke[0]), -np.array(stroke[1]))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "DF93HB1aGeGb"}, "source": ["## Rasterize\n", "\n", "Idea: After converting the raw drawing data into rasterized images, we can\n", "use [MNIST](https://www.tensorflow.org/tutorials/quickstart/beginner)-like\n", "image processing to classify the drawings."]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "AVsC-4hcGeGc", "colab": {}}, "source": ["def dict_to_img(drawing, img_sz=64, lw=3, maximize=True):\n", "  \"\"\"Converts QuickDraw data to quadratic rasterized image.\n", "  \n", "  Args:\n", "    drawing: Dictionary instance of QuickDraw dataset.\n", "    img_sz: Size output image (in pixels).\n", "    lw: Line width (in pixels).\n", "    maximize: Whether to maximize drawing within image pixels.\n", "    \n", "  Returns:\n", "    A PIL.Image with the rasterized drawing.\n", "  \"\"\"\n", "  img = Image.new('L', (img_sz, img_sz))\n", "  draw = ImageDraw.Draw(img)\n", "  lines = np.array([\n", "      stroke[0:2, i:i+2]\n", "      for stroke in drawing['drawing']\n", "      for i in range(stroke.shape[1] - 1)\n", "  ], dtype=np.float32)\n", "  if maximize:\n", "    for i in range(2):\n", "      min_, max_ = lines[:,i,:].min() * 0.95, lines[:,i,:].max() * 1.05\n", "      lines[:,i,:] = (lines[:,i,:] - min_) / max(max_ - min_, 1)\n", "  else:\n", "    lines /= 1024\n", "  for line in lines:\n", "    draw.line(tuple(line.T.reshape((-1,)) * img_sz), fill='white', width=lw)\n", "  return img"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "K4GzMB12GeGf", "outputId": "0eef5f33-e06a-43fb-f9d8-c248d6d5e6f5", "executionInfo": {"status": "ok", "timestamp": 1579992737301, "user_tz": 480, "elapsed": 99884, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 742}}, "source": ["# Show some examples.\n", "\n", "def showimg(img):\n", "  \"\"\"Shows an image with an inline HTML <img> tag.\n", "  \n", "  Args:\n", "    img: Can be a PIL.Image or a numpy.ndarray.\n", "  \"\"\"\n", "  if isinstance(img, np.ndarray):\n", "    img = Image.fromarray(img, 'L')\n", "  b = io.BytesIO()\n", "  img.convert('RGB').save(b, format='png')\n", "  enc = base64.b64encode(b.getvalue()).decode('utf-8')\n", "  display.display(display.HTML(\n", "      '<img src=\"data:image/png;base64,%s\">' % enc))\n", "\n", "# Fetch some images + shuffle order.\n", "rows, cols = len(labels), 10\n", "n_per_class = rows * cols // len(labels) + 1\n", "drawings_list = [drawing for name in labels\n", "                 for drawing in loadn(name, cols)]\n", "\n", "# Create mosaic of rendered images.\n", "lw = 4\n", "img_sz = 64\n", "tableau = np.zeros((img_sz * rows, img_sz * cols), dtype=np.uint8)\n", "for y in range(rows):\n", "  for x in range(cols):\n", "    i = y * cols + x\n", "    img = dict_to_img(drawings_list[i], img_sz=img_sz, lw=lw, maximize=True)\n", "    tableau[y*img_sz:(y+1)*img_sz,\n", "            x*img_sz:(x+1)*img_sz] = np.asarray(img)\n", "\n", "showimg(tableau)\n", "print('{} samples of : {}'.format(cols, ' '.join(labels)))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "gW40he1tGeGi"}, "source": ["## Protobufs and tf.train.Example\n", "\n", "Tensorflow's \"native\" format for data storage is the `tf.train.Example`\n", "[protocol buffer](https://en.wikipedia.org/wiki/Protocol_Buffers).\n", "\n", "In this section we briefly explore the API needed to access the data\n", "inside the `tf.train.Example` protocol buffer. It's **not necessary** to read\n", "through the\n", "[Protocol Buffer Basics: Python - documentation](https://developers.google.com/protocol-buffers/docs/pythontutorial)."]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "BB8g-Tb1GeGn", "outputId": "d7316392-0ab2-4617-94dd-717d6dd9b918", "executionInfo": {"status": "ok", "timestamp": 1579992737301, "user_tz": 480, "elapsed": 99881, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 443}}, "source": ["# Create a new (empty) instance.\n", "example = tf.train.Example()\n", "\n", "# An empty example will not print anything.\n", "print(example)\n", "\n", "# An example contains a map from feature name to \"Feature\".\n", "# Every \"Feature\" contains a list of elements of the same\n", "# type, which is one of:\n", "# - bytes_list (similar to Python's \"str\")\n", "# - float_list (float number)\n", "# - int64_list (integer number)\n", "\n", "# These values can be accessed as follows (no need to understand\n", "# details):\n", "# Add float value \"3.1416\" to feature \"magic_numbers\"\n", "example.features.feature['magic_numbers'].float_list.value.append(3.1416)\n", "# Add some more values to the float list \"magic_numbers\".\n", "example.features.feature['magic_numbers'].float_list.value.extend([2.7183, 1.4142, 1.6180])\n", "\n", "### YOUR ACTION REQUIRED:\n", "# Create a second feature named \"adversaries\" and add the elements\n", "# b'Alice' and b'Bob'.\n", "example.features.feature['adversaries'].\n", "\n", "# This will now print a serialized representation of our protocol buffer\n", "# with features \"magic_numbers\" and \"adversaries\" set...\n", "print(example)\n", "\n", "# .. et voila : that's all you need to know about protocol buffers for this\n", "# workshop."], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "33imDs6YGeGq"}, "source": ["## Create datasets\n", "\n", "Now let's create a \"dataset\" of `tf.train.Example`\n", "[protocol buffers](https://developers.google.com/protocol-buffers/) (\"protos\").\n", "\n", "A single example will contain all the information we want to use for training for a drawing (i.e. rasterized\n", "image, label, and maybe other information)."]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "Ef_i5QFWGeGq", "outputId": "76c091cb-42f8-4a19-b325-ac85face8ed6", "executionInfo": {"status": "ok", "timestamp": 1579992828398, "user_tz": 480, "elapsed": 190976, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 212}}, "source": ["# Let's first check how many [recognized=True] examples we have in each class.\n", "for name in labels:\n", "  num_all_samples = len(list(tf.io.gfile.GFile('%s/%s.ndjson' % (data_path, name))))\n", "  num_recognized_samples = len(list(loaditer(name)))\n", "  print(name, num_all_samples, 'recognized', num_recognized_samples)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "146TnInkYMhN", "colab_type": "text"}, "source": ["**Sharding**\n", "\n", "A dataset consists of non-overlapping sets of examples that will be used for\n", "training and evaluation of the classifier (the \"test\" set will be used for the\n", "final evaluation). As these files can quickly become very large, we split them into smaller files referred to as *shards*.\n", "For example, we could split a single dataset into a number of *shards*, like\n", "* train-00000-of-00005,\n", "* train-00001-of-00005,\n", "*  ...,\n", "* train-00004-of-00005 (if we're using 5 shards).\n", "\n", "This way we have smaller individual files, and we can also easily access for example only 20% of all data, or have 5 threads which read through all the data\n", "simultaneously.\n", "\n", "Generally, with large datasets, a recommendation is to split data into individual *shards* with a size of ~100 MB each. This workshop might use smaller sharding sizes for simplicity reasons. "]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "r4h9W4JvGeGt", "cellView": "both", "colab": {}}, "source": ["#@title `make_sharded_files()` code\n", "#@markdown Helper code to create sharded recordio files.\n", "#@markdown Simply **click \"execute\"** and continue to the next cell.\n", "#@markdown No need to read through this code to understand the remainder of the Colab.\n", "#@markdown \n", "#@markdown If you want to have a look anyways, you can double-click this cell or click on the three dots\n", "#@markdown and then select \"Form\" and then \"Show Code\" (shortcut `<Ctrl-M> <F>`).\n", "\n", "# Helper code to create sharded recordio files.\n", "# (No need to read through this.)\n", "\n", "# The code in this cell simply takes a list of iterators and then\n", "# randomly distributes the values returned by these iterators into sharded\n", "# datasets (e.g. a train/eval/test split).\n", "\n", "def rand_key(counts):\n", "  \"\"\"Returns a random key from \"counts\", using values as distribution.\"\"\"\n", "  r = random.randint(0, sum(counts.values()))\n", "  for key, count in counts.items():\n", "    if r > count or count == 0:\n", "      r -= count\n", "    else:\n", "      counts[key] -= 1\n", "      return key\n", "\n", "def get_split(i, splits):\n", "  \"\"\"Returns key from \"splits\" for iteration \"i\".\"\"\"\n", "  i %= sum(splits.values())\n", "  for split in sorted(splits):\n", "    if i < splits[split]:\n", "      return split\n", "    i -= splits[split]\n", "\n", "def make_counts(labels, total):\n", "  \"\"\"Generates counts for \"labels\" totaling \"total\".\"\"\"\n", "  counts = {}\n", "  for i, name in enumerate(labels):\n", "    counts[name] = total // (len(labels) - i)\n", "    total -= counts[name]\n", "  return counts\n", "\n", "def example_to_dict(example):\n", "  \"\"\"Converts a tf.train.Example to a dictionary.\"\"\"\n", "  example_dict = {}\n", "  for name, value in example.features.feature.items():\n", "    if value.HasField('bytes_list'):\n", "      value = value.bytes_list.value\n", "    elif value.HasField('int64_list'):\n", "      value = value.int64_list.value\n", "    elif value.HasField('float_list'):\n", "      value = value.float_list.value\n", "    else:\n", "      raise 'Unknown *_list type!'\n", "    if len(value) == 1:\n", "      example_dict[name] = value[0]\n", "    else:\n", "      example_dict[name] = np.array(value)\n", "  return example_dict\n", "\n", "def make_sharded_files(make_example, path, labels, iters, counts, splits,\n", "                       shards=10, overwrite=False, report_dt=10, make_df=False):\n", "  \"\"\"Create sharded dataset from \"iters\".\n", "\n", "  Args:\n", "    make_example: Converts object returned by elements of \"iters\"\n", "        to tf.train.Example() proto.\n", "    path: Directory that will contain recordio files.\n", "    labels: Names of labels, will be written to \"labels.txt\".\n", "    iters: List of iterables returning drawing objects.\n", "    counts: Dictionary mapping class to number of examples.\n", "    splits: Dictionary mapping filename to multiple examples. For example,\n", "        splits=dict(a=2, b=1) will result in two examples being written to \"a\"\n", "        for every example being written to \"b\".\n", "    shards: Number of files to be created per split.\n", "    overwrite: Whether a pre-existing directory should be overwritten.\n", "    report_dt: Number of seconds between status updates (0=no updates).\n", "    make_df: Also write data as pandas.DataFrame - do NOT use this with very\n", "        large datasets that don't fit in memory!\n", "\n", "  Returns:\n", "    Total number of examples written to disk per split.\n", "  \"\"\"\n", "  assert len(iters) == len(labels)\n", "  # Prepare output.\n", "  if not tf.io.gfile.exists(path):\n", "    tf.io.gfile.makedirs(path)\n", "  paths = {\n", "      split: ['%s/%s-%05d-of-%05d' % (path, split, i, shards)\n", "              for i in range(shards)]\n", "      for split in splits\n", "  }\n", "  assert overwrite or not tf.io.gfile.exists(paths.values()[0][0])\n", "  writers = {\n", "      split: [tf.io.TFRecordWriter(ps[i]) for i in range(shards)]\n", "      for split, ps in paths.items()\n", "  }\n", "  t0 = time.time()\n", "  examples_per_split = collections.defaultdict(int)\n", "  i, n = 0, sum(counts.values())\n", "  counts = dict(**counts)\n", "  rows = []\n", "  # Create examples.\n", "  while sum(counts.values()):\n", "    name = rand_key(counts)\n", "    split = get_split(i, splits)\n", "    writer = writers[split][examples_per_split[split] % shards]\n", "    label = labels.index(name)\n", "    example = make_example(label, next(iters[label]))\n", "    writer.write(example.SerializeToString())\n", "    if make_df:\n", "      example.features.feature['split'].bytes_list.value.append(split.encode('utf8'))\n", "      rows.append(example_to_dict(example))\n", "    examples_per_split[split] += 1\n", "    i += 1\n", "    if report_dt > 0 and time.time() - t0 > report_dt:\n", "      print('processed %d/%d (%.2f%%)' % (i, n, 100. * i / n))\n", "      t0 = time.time()\n", "  # Store results.\n", "  for split in splits:\n", "    for writer in writers[split]:\n", "      writer.close()\n", "  with tf.io.gfile.GFile('%s/labels.txt' % path, 'w') as f:\n", "    f.write('\\n'.join(labels))\n", "  with tf.io.gfile.GFile('%s/counts.json' % path, 'w') as f:\n", "    json.dump(examples_per_split, f)\n", "  if make_df:\n", "    df_path = '%s/dataframe.pkl' % path\n", "    print('Writing %s...' % df_path)\n", "    pd.DataFrame(rows).to_pickle(df_path)\n", "  return dict(**examples_per_split)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Ecj5-3EGKXOd", "colab_type": "text"}, "source": ["### Create IMG dataset"]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "uPF9vIipGeGv", "colab": {}}, "source": ["# Uses dict_to_img() from previous cell to create raster image.\n", "\n", "def make_example_img(label, drawing):\n", "  \"\"\"Converts QuickDraw dictionary to example with rasterized data.\n", "  \n", "  Args:\n", "    label: Numerical representation of the label (e.g. '0' for labels[0]).\n", "    drawing: Dictionary with QuickDraw data.\n", "\n", "  Returns:\n", "    A tf.train.Example protocol buffer (with 'label', 'img_64', and additional\n", "    metadata features).\n", "  \"\"\"\n", "  example = tf.train.Example()\n", "  example.features.feature['label'].int64_list.value.append(label)\n", "  img_64 = np.asarray(dict_to_img(\n", "      drawing, img_sz=64, lw=4, maximize=True)).reshape(-1)\n", "  example.features.feature['img_64'].int64_list.value.extend(img_64)\n", "  example.features.feature['countrycode'].bytes_list.value.append(\n", "      drawing['countrycode'].encode())\n", "  example.features.feature['recognized'].int64_list.value.append(\n", "      drawing['recognized'])\n", "  example.features.feature['word'].bytes_list.value.append(\n", "      drawing['word'].encode())\n", "  ts = drawing['timestamp']\n", "  ts = time.mktime(time.strptime(ts[:ts.index('.')], '%Y-%m-%d %H:%M:%S'))\n", "  example.features.feature['timestamp'].int64_list.value.append(int(ts))\n", "  example.features.feature['key_id'].int64_list.value.append(\n", "      int(drawing['key_id']))\n", "  return example"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "VhCUj9uGiPov", "colab_type": "text"}, "source": ["We will now create a dataset with 80k samples consisting of:\n", "\n", "*   50k samples used for training\n", "*   20k samples used for evaluation\n", "*   10k samples used for testing\n", "\n", "The generation below will take about **~5 minutes**.\n", "\n", "> **Note:** Larger datasets take longer to generate and to train on, but also lead to better classification results.\n", "\n"]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "ksR9Hw0DGeGy", "outputId": "2ce5e543-4d88-4340-b2f8-c6471f762ac4", "executionInfo": {"status": "ok", "timestamp": 1579993157563, "user_tz": 480, "elapsed": 520133, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 478}}, "source": ["# Create the (rasterized) dataset.\n", "\n", "path = '%s/%s_img' % (data_path, dataset_name)\n", "t0 = time.time()\n", "examples_per_split = make_sharded_files(\n", "    make_example=make_example_img,\n", "    path=path,\n", "    labels=labels,\n", "    iters=[loaditer(name) for name in labels],\n", "    # Creating 50k train, 20k eval and 10k test examples.\n", "    counts=make_counts(labels, 80000),\n", "    splits=dict(train=5, eval=2, test=1),\n", "    overwrite=True,\n", "    # Note: Set this to False when generating large datasets.\n", "    make_df=True,\n", ")\n", "\n", "# If you don't see the final output below, it's probably because your VM\n", "# has run out of memory and crashed!\n", "# This can happen when make_df=True.\n", "print('stored data to \"%s\"' % path)\n", "print('generated %s examples in %d seconds' % (\n", "    examples_per_split, time.time() - t0))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "s-MmsFVFGeG1"}, "source": ["### Create STROKE dataset\n", "\n", "This section creates another dataset of example protos that contain the raw\n", "stroke data, suitable for usage with a recurrent neural network."]}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "c1SCR8h1GeG2", "colab": {}}, "source": ["# Convert stroke coordinates into normalized relative coordinates,\n", "# one single list, and add a \"third dimension\" that indicates when\n", "# a new stroke starts.\n", "\n", "def dict_to_stroke(d):\n", "  norm = lambda x: (x - x.min()) / max(1, (x.max() - x.min()))\n", "  xy = np.concatenate([np.array(s, dtype=np.float32) for \n", "                       s in d['drawing']], axis=1)\n", "  z = np.zeros(xy.shape[1])\n", "  if len(d['drawing']) > 1:\n", "    z[np.cumsum(np.array(list(map(lambda x: x.shape[1], \n", "                                  d['drawing'][:-1]))))] = 1\n", "  dxy = np.diff(norm(xy))\n", "  return np.concatenate([dxy, z.reshape((1, -1))[:, 1:]])"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "QC1U8kZ8GeG4", "outputId": "0c85c21a-02f1-4e4e-c8e6-7775811d53f4", "executionInfo": {"status": "ok", "timestamp": 1579993157745, "user_tz": 480, "elapsed": 520309, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 264}}, "source": ["# Visualize and control output of dict_to_stroke().\n", "\n", "stroke = dict_to_stroke(sample[0])\n", "# The first 2 dimensions are normalized dx/dy coordinates, and\n", "# the third dimension indicates a new stroke.\n", "xy = stroke[:2, :].cumsum(axis=1)\n", "plt.plot(xy[0,:], -xy[1,:])\n", "pxy = xy[:, stroke[2] != 0]\n", "# Indicate the new stroke with a red circle.\n", "plt.plot(pxy[0], -pxy[1], 'ro');"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab_type": "code", "id": "rxzZZyR9GeG8", "colab": {}}, "source": ["# Uses dict_to_stroke() from previous cell to create raster image.\n", "\n", "def make_example_stroke(label, drawing):\n", "  \"\"\"Converts QuickDraw dictionary to example with stroke data.\n", "\n", "  Args:\n", "    label: Numerical representation of the label (e.g. '0' for labels[0]).\n", "    drawing: Dictionary with QuickDraw data.\n", "\n", "  Returns:\n", "    A tf.train.Example protocol buffer (with 'label', 'stroke_x', 'stroke_y',\n", "    'stroke_z', and additional metadata features).\n", "  \"\"\"\n", "  example = tf.train.Example()\n", "  example.features.feature['label'].int64_list.value.append(label)\n", "  stroke = dict_to_stroke(drawing)\n", "  example.features.feature['stroke_x'].float_list.value.extend(stroke[0, :])\n", "  example.features.feature['stroke_y'].float_list.value.extend(stroke[1, :])\n", "  example.features.feature['stroke_z'].float_list.value.extend(stroke[2, :])\n", "  example.features.feature['stroke_len'].int64_list.value.append(\n", "      stroke.shape[1])\n", "  example.features.feature['countrycode'].bytes_list.value.append(\n", "      drawing['countrycode'].encode())\n", "  example.features.feature['recognized'].int64_list.value.append(\n", "      drawing['recognized'])\n", "  example.features.feature['word'].bytes_list.value.append(\n", "      drawing['word'].encode())\n", "  ts = drawing['timestamp']\n", "  ts = time.mktime(time.strptime(ts[:ts.index('.')], '%Y-%m-%d %H:%M:%S'))\n", "  example.features.feature['timestamp'].int64_list.value.append(int(ts))\n", "  example.features.feature['key_id'].int64_list.value.append(\n", "      int(drawing['key_id']))\n", "  return example"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "A7LyQXCv3ADO", "colab_type": "code", "outputId": "37627ccf-d777-4de2-e6fe-fbc4105380ba", "executionInfo": {"status": "ok", "timestamp": 1579993222170, "user_tz": 480, "elapsed": 584729, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 141}}, "source": ["path = '%s/%s_stroke' % (data_path, dataset_name)\n", "t0 = time.time()\n", "examples_per_split = make_sharded_files(\n", "    make_example=make_example_stroke,\n", "    path=path,\n", "    labels=labels,\n", "    iters=[loaditer(name) for name in labels],\n", "    # Creating 50k train, 20k eval, 10k test examples. Takes ~2min\n", "    counts=make_counts(labels, 80000),\n", "    splits=dict(train=5, eval=2, test=1),\n", "    overwrite=True,\n", "    # Note : Set this to False when generating large datasets...\n", "    make_df=True,\n", ")\n", "\n", "print('stored data to \"%s\"' % path)\n", "print('generated %s examples in %d seconds' % (examples_per_split, time.time() - t0))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Kqkg17PxIhrJ", "colab_type": "text"}, "source": ["# ----- Optional part -----"]}, {"cell_type": "markdown", "metadata": {"id": "V1oCjDZhb2do", "colab_type": "text"}, "source": ["## Inspect data"]}, {"cell_type": "code", "metadata": {"id": "8aUJmZuUb5JH", "colab_type": "code", "outputId": "3d6c57e0-2715-4ee9-b2ac-92395d318529", "executionInfo": {"status": "ok", "timestamp": 1579993223404, "user_tz": 480, "elapsed": 585960, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 1000}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Check out the files generated in $data_path\n", "\n", "# Note that you can also inspect the files in http://drive.google.com if you\n", "# used Drive as the destination.\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "jq3yJWKMcQdV", "colab_type": "code", "outputId": "e2f1151d-6423-40a5-cc76-cc0e30ba9c08", "executionInfo": {"status": "ok", "timestamp": 1579993224862, "user_tz": 480, "elapsed": 587416, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 54}}, "source": ["# Let's look at a single file of the sharded dataset.\n", "tf_record_path = '{}/{}_img/eval-00000-of-00010'.format(data_path, dataset_name)\n", "# YOUR ACTION REQUIRED:\n", "# Use tf.data.TFRecordDataset() to read a single record from the file and assign\n", "# it to the variable `record`. What data type has this record?\n", "# Hint: dataset is a Python \"iterable\".\n", "#dataset = ...\n", "#record\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "KvAUIAn6d5ow", "colab_type": "code", "outputId": "9870829b-72c4-487a-f993-53df9bed83e2", "executionInfo": {"status": "ok", "timestamp": 1579993224863, "user_tz": 480, "elapsed": 587414, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["# Check out the features. They should correspond to what we generated in\n", "# make_example_img() above.\n", "example = tf.train.Example()\n", "# Note: .numpy() returns the underlying string from the Tensor.\n", "example.ParseFromString(record.numpy())\n", "print(list(example.features.feature.keys()))"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "BDGmgNQ7dgOz", "colab_type": "code", "colab": {}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Extract the label and the image data from the example protobuf.\n", "# Use above section \"tf.train.Example\" for reference.\n", "label_int =\n", "img_64 = \n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "3e0Dwc09efDD", "colab_type": "code", "outputId": "36b68f77-7abf-4fa1-9e84-1be3f7739931", "executionInfo": {"status": "ok", "timestamp": 1579993225114, "user_tz": 480, "elapsed": 587657, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 310}}, "source": ["# Visualize the image:\n", "print(labels[label_int])\n", "plt.matshow(np.array(img_64).reshape((64, 64)))"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "YhfIKXXChrab", "colab_type": "code", "outputId": "31d9788d-80db-4a7c-d9cb-14e833baab7c", "executionInfo": {"status": "ok", "timestamp": 1579993225767, "user_tz": 480, "elapsed": 588304, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 353}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Check that we have an equal distribution of labels in the training files.\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "lI01xshyjTbH", "colab_type": "text"}, "source": ["## More on protobufs"]}, {"cell_type": "code", "metadata": {"id": "aGej8L70W7AH", "colab_type": "code", "outputId": "bfe9f345-6451-410e-c220-0306ae105fcb", "executionInfo": {"status": "ok", "timestamp": 1579993238873, "user_tz": 480, "elapsed": 601407, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 1000}}, "source": ["# If we want to create our own protocol buffers, we first need to install\n", "# some programs.\n", "!apt-get -y install protobuf-compiler python-pil python-lxml"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "lkF7qlk3XwA2", "colab_type": "code", "colab": {}}, "source": ["# Step 1: Write a proto file that describes our data format.\n", "# YOUR ACTION REQUIRED: Complete the definition of the \"Person\" message (you\n", "# can use the slide for inspiration).\n", "with open('person.proto', 'w') as f:\n", "  f.write('''syntax = \"proto3\";''')\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "pBAJaBXBXwrH", "colab_type": "code", "outputId": "80579f75-b42e-4610-decd-b59331ed75eb", "executionInfo": {"status": "ok", "timestamp": 1579994065914, "user_tz": 480, "elapsed": 2695, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 123}}, "source": ["# Step 2: Compile proto definition to a Python file.\n", "!protoc --python_out=. person.proto\n", "!ls -lh"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "2T9fzSImX_M1", "colab_type": "code", "colab": {}}, "source": ["# Step 3: Import code from generated Python file.\n", "from person_pb2 import Person\n", "# Note: If you change the person_pb2 module, you'll need to restart the kernel\n", "# to see the changes because Python will still remember the previous import..."], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "gvOO-6qxX_8E", "colab_type": "code", "outputId": "f4462025-04e2-4b50-a375-405f4a9d16b3", "executionInfo": {"status": "ok", "timestamp": 1579994065916, "user_tz": 480, "elapsed": 2402, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 34}}, "source": ["person = Person()\n", "person.name = 'John Doe'\n", "person.email = 'john.doe@gmail.com'\n", "person.lucky_numbers.extend([13, 99])\n", "person.SerializeToString()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "jyrH9BxLZsrf", "colab_type": "code", "outputId": "742cea53-1ffb-496c-c3db-176ac2decc7a", "executionInfo": {"status": "ok", "timestamp": 1579994068259, "user_tz": 480, "elapsed": 497, "user": {"displayName": "Andreas Steiner", "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAYx167H2vNmFSKlsQkQY-bjbJ-3sPGymaG0kXO=s64", "userId": "08860260976100898876"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 52}}, "source": ["# YOUR ACTION REQUIRED:\n", "# Compare the size of the serialized person structure in proto format\n", "# vs. JSON encoded (you can use Python's json.dumps() and list members\n", "# manually, or import google.protobuf.json_format).\n", "\n", "# Which format is more efficient? Why?\n", "# Which format is easier to use?\n", "# Which format is more versatile?\n"], "execution_count": null, "outputs": []}]}